{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.utils import to_categorical, image_dataset_from_directory\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "matplotlib.use('Agg')   # type: ignore\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset directory\n",
    "images_dir = \"images\"\n",
    "# \"C:/Users/theof/OneDrive/Documents/Github/genome_color_unpickler/train-raw/arrays\"\n",
    "\n",
    "# Training parameters\n",
    "img_size = (32, 32)\n",
    "batch_size = 32\n",
    "epochs = 15\n",
    "\n",
    "# Dictionary to store accuracies\n",
    "max_accuracies = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build a simple CNN model\n",
    "def cnn_model(input_shape, num_classes):\n",
    "\tmodel = Sequential([\n",
    "\t\tConv2D(32, (5,5), activation='relu', input_shape=input_shape),\n",
    "\t\tMaxPooling2D(2,2),\n",
    "\t\tConv2D(64, (5,5), activation='relu'),\n",
    "\t\tMaxPooling2D(2,2),\n",
    "\t\tFlatten(),\n",
    "\t\tDense(128, activation='relu'),\n",
    "\t\tDense(num_classes, activation='softmax')  # Adjust output neurons based on classes\n",
    "\t])\n",
    "\tmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training 4px/Chargaff-Composante-Diversite...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 5s 26ms/step - loss: 0.9656 - accuracy: 0.6545 - val_loss: 0.9599 - val_accuracy: 0.6516\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.9076 - accuracy: 0.6675 - val_loss: 0.9369 - val_accuracy: 0.6280\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.8899 - accuracy: 0.6822 - val_loss: 0.9463 - val_accuracy: 0.6746\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.8822 - accuracy: 0.6902 - val_loss: 0.9814 - val_accuracy: 0.6531\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.8691 - accuracy: 0.6889 - val_loss: 0.8956 - val_accuracy: 0.6716\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.8639 - accuracy: 0.6903 - val_loss: 0.8720 - val_accuracy: 0.6938\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.8544 - accuracy: 0.6948 - val_loss: 0.9064 - val_accuracy: 0.6701\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.8435 - accuracy: 0.6998 - val_loss: 0.8901 - val_accuracy: 0.6627\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.8324 - accuracy: 0.7051 - val_loss: 0.9232 - val_accuracy: 0.6901\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.8321 - accuracy: 0.7066 - val_loss: 0.8776 - val_accuracy: 0.6701\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.8273 - accuracy: 0.7064 - val_loss: 0.8617 - val_accuracy: 0.7049\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.8256 - accuracy: 0.7105 - val_loss: 0.8577 - val_accuracy: 0.6960\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.8162 - accuracy: 0.7153 - val_loss: 0.9804 - val_accuracy: 0.6753\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.8223 - accuracy: 0.7073 - val_loss: 0.8767 - val_accuracy: 0.6923\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.8075 - accuracy: 0.7127 - val_loss: 0.8486 - val_accuracy: 0.6960\n",
      "Model saved to models/standard\\4px\\Chargaff-Composante-Diversite\n",
      "Validation accuracy for 4px - Chargaff-Composante-Diversite: 0.7049\n",
      "\n",
      "Training 4px/Chargaff-Composante-NucleScore...\n",
      "Found 5419 images belonging to 5 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\theof\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 5s 26ms/step - loss: 0.9973 - accuracy: 0.6468 - val_loss: 0.9626 - val_accuracy: 0.6516\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.9712 - accuracy: 0.6512 - val_loss: 0.9469 - val_accuracy: 0.6516\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.9078 - accuracy: 0.6828 - val_loss: 0.8151 - val_accuracy: 0.7448\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.8836 - accuracy: 0.7057 - val_loss: 0.8232 - val_accuracy: 0.7389\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.8583 - accuracy: 0.7247 - val_loss: 0.7937 - val_accuracy: 0.7485\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.8533 - accuracy: 0.7226 - val_loss: 0.8015 - val_accuracy: 0.7567\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.8448 - accuracy: 0.7346 - val_loss: 0.8078 - val_accuracy: 0.7470\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.8536 - accuracy: 0.7234 - val_loss: 0.8301 - val_accuracy: 0.7041\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 4s 21ms/step - loss: 0.8491 - accuracy: 0.7250 - val_loss: 0.8484 - val_accuracy: 0.7286\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.8363 - accuracy: 0.7319 - val_loss: 0.7848 - val_accuracy: 0.7567\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.8280 - accuracy: 0.7380 - val_loss: 0.7996 - val_accuracy: 0.7522\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.8413 - accuracy: 0.7306 - val_loss: 0.8213 - val_accuracy: 0.7419\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.8144 - accuracy: 0.7461 - val_loss: 0.8094 - val_accuracy: 0.7241\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.8168 - accuracy: 0.7442 - val_loss: 0.7739 - val_accuracy: 0.7581\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.8200 - accuracy: 0.7404 - val_loss: 0.8107 - val_accuracy: 0.7404\n",
      "Model saved to models/standard\\4px\\Chargaff-Composante-NucleScore\n",
      "Validation accuracy for 4px - Chargaff-Composante-NucleScore: 0.7581\n",
      "\n",
      "Training 4px/Chargaff-Diversite-NucleScore...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 5s 26ms/step - loss: 0.9587 - accuracy: 0.6592 - val_loss: 0.9544 - val_accuracy: 0.6494\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.9073 - accuracy: 0.6658 - val_loss: 0.9528 - val_accuracy: 0.6501\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.8871 - accuracy: 0.6780 - val_loss: 0.9135 - val_accuracy: 0.6820\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.8278 - accuracy: 0.7118 - val_loss: 0.8468 - val_accuracy: 0.6982\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.7981 - accuracy: 0.7437 - val_loss: 0.7742 - val_accuracy: 0.7322\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.7777 - accuracy: 0.7536 - val_loss: 0.8207 - val_accuracy: 0.7152\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.7556 - accuracy: 0.7581 - val_loss: 0.7781 - val_accuracy: 0.7182\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.7547 - accuracy: 0.7577 - val_loss: 0.7611 - val_accuracy: 0.7263\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.7382 - accuracy: 0.7667 - val_loss: 0.7620 - val_accuracy: 0.7337\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.7392 - accuracy: 0.7655 - val_loss: 0.7531 - val_accuracy: 0.7463\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.7321 - accuracy: 0.7664 - val_loss: 0.7510 - val_accuracy: 0.7456\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.7287 - accuracy: 0.7660 - val_loss: 0.7667 - val_accuracy: 0.7293\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.7295 - accuracy: 0.7643 - val_loss: 0.7617 - val_accuracy: 0.7589\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.7181 - accuracy: 0.7723 - val_loss: 0.7585 - val_accuracy: 0.7426\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.7146 - accuracy: 0.7723 - val_loss: 0.7384 - val_accuracy: 0.7441\n",
      "Model saved to models/standard\\4px\\Chargaff-Diversite-NucleScore\n",
      "Validation accuracy for 4px - Chargaff-Diversite-NucleScore: 0.7589\n",
      "\n",
      "Training 4px/Chargaff-Skew-Composante...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 5s 26ms/step - loss: 0.9932 - accuracy: 0.6510 - val_loss: 0.9749 - val_accuracy: 0.6516\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.9777 - accuracy: 0.6510 - val_loss: 0.9717 - val_accuracy: 0.6516\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.9797 - accuracy: 0.6510 - val_loss: 0.9687 - val_accuracy: 0.6516\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.9699 - accuracy: 0.6510 - val_loss: 0.9721 - val_accuracy: 0.6516\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.9735 - accuracy: 0.6510 - val_loss: 0.9710 - val_accuracy: 0.6516\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 4s 21ms/step - loss: 0.9611 - accuracy: 0.6525 - val_loss: 0.9526 - val_accuracy: 0.6516\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.9589 - accuracy: 0.6510 - val_loss: 0.9655 - val_accuracy: 0.6775\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.9477 - accuracy: 0.6566 - val_loss: 0.9490 - val_accuracy: 0.6760\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.9481 - accuracy: 0.6558 - val_loss: 0.9383 - val_accuracy: 0.6768\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.9479 - accuracy: 0.6632 - val_loss: 0.9225 - val_accuracy: 0.6731\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.9439 - accuracy: 0.6617 - val_loss: 0.9190 - val_accuracy: 0.6827\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.9455 - accuracy: 0.6669 - val_loss: 0.9717 - val_accuracy: 0.6694\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.9414 - accuracy: 0.6675 - val_loss: 0.9254 - val_accuracy: 0.7071\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.9395 - accuracy: 0.6671 - val_loss: 0.9161 - val_accuracy: 0.7056\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.9357 - accuracy: 0.6669 - val_loss: 0.9089 - val_accuracy: 0.7056\n",
      "Model saved to models/standard\\4px\\Chargaff-Skew-Composante\n",
      "Validation accuracy for 4px - Chargaff-Skew-Composante: 0.7071\n",
      "\n",
      "Training 4px/Chargaff-Skew-Diversite...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 4s 23ms/step - loss: 0.9544 - accuracy: 0.6470 - val_loss: 0.9408 - val_accuracy: 0.6265\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.9106 - accuracy: 0.6623 - val_loss: 0.9549 - val_accuracy: 0.6354\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 16ms/step - loss: 0.9000 - accuracy: 0.6671 - val_loss: 0.9263 - val_accuracy: 0.6250\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.8959 - accuracy: 0.6656 - val_loss: 0.9498 - val_accuracy: 0.6368\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.8920 - accuracy: 0.6710 - val_loss: 0.9359 - val_accuracy: 0.6368\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.8790 - accuracy: 0.6793 - val_loss: 0.9425 - val_accuracy: 0.6420\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.8821 - accuracy: 0.6752 - val_loss: 0.9301 - val_accuracy: 0.6435\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.8732 - accuracy: 0.6848 - val_loss: 0.9342 - val_accuracy: 0.6435\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 16ms/step - loss: 0.8759 - accuracy: 0.6820 - val_loss: 0.9131 - val_accuracy: 0.6575\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.8642 - accuracy: 0.6809 - val_loss: 0.9364 - val_accuracy: 0.6428\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 16ms/step - loss: 0.8675 - accuracy: 0.6809 - val_loss: 0.9831 - val_accuracy: 0.6524\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.8677 - accuracy: 0.6833 - val_loss: 0.9475 - val_accuracy: 0.6413\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.8543 - accuracy: 0.6931 - val_loss: 0.9223 - val_accuracy: 0.6442\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.8553 - accuracy: 0.6924 - val_loss: 0.9183 - val_accuracy: 0.6376\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.8452 - accuracy: 0.6974 - val_loss: 0.9106 - val_accuracy: 0.6583\n",
      "Model saved to models/standard\\4px\\Chargaff-Skew-Diversite\n",
      "Validation accuracy for 4px - Chargaff-Skew-Diversite: 0.6583\n",
      "\n",
      "Training 4px/Chargaff-Skew-NucleScore...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 4s 23ms/step - loss: 0.9975 - accuracy: 0.6472 - val_loss: 0.9832 - val_accuracy: 0.6516\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 16ms/step - loss: 0.9870 - accuracy: 0.6510 - val_loss: 1.0133 - val_accuracy: 0.6516\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 16ms/step - loss: 0.9809 - accuracy: 0.6510 - val_loss: 0.9902 - val_accuracy: 0.6516\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.9764 - accuracy: 0.6510 - val_loss: 0.9723 - val_accuracy: 0.6516\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.9772 - accuracy: 0.6510 - val_loss: 0.9733 - val_accuracy: 0.6516\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.9730 - accuracy: 0.6510 - val_loss: 0.9577 - val_accuracy: 0.6516\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.9687 - accuracy: 0.6510 - val_loss: 0.9596 - val_accuracy: 0.6516\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.9612 - accuracy: 0.6520 - val_loss: 0.9365 - val_accuracy: 0.6516\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.9234 - accuracy: 0.6684 - val_loss: 0.8508 - val_accuracy: 0.7041\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.8768 - accuracy: 0.7018 - val_loss: 0.8225 - val_accuracy: 0.7426\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.8565 - accuracy: 0.7226 - val_loss: 0.8189 - val_accuracy: 0.7507\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.8498 - accuracy: 0.7221 - val_loss: 0.8040 - val_accuracy: 0.7382\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.8539 - accuracy: 0.7208 - val_loss: 0.7877 - val_accuracy: 0.7574\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.8268 - accuracy: 0.7372 - val_loss: 0.7899 - val_accuracy: 0.7522\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.8295 - accuracy: 0.7378 - val_loss: 0.7697 - val_accuracy: 0.7559\n",
      "Model saved to models/standard\\4px\\Chargaff-Skew-NucleScore\n",
      "Validation accuracy for 4px - Chargaff-Skew-NucleScore: 0.7574\n",
      "\n",
      "Training 4px/Composante-Diversite-NucleScore...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 5s 26ms/step - loss: 0.9665 - accuracy: 0.6470 - val_loss: 0.9603 - val_accuracy: 0.6405\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.9136 - accuracy: 0.6621 - val_loss: 0.9289 - val_accuracy: 0.6457\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.8948 - accuracy: 0.6688 - val_loss: 0.9515 - val_accuracy: 0.6494\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.8923 - accuracy: 0.6728 - val_loss: 0.9409 - val_accuracy: 0.6501\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.8750 - accuracy: 0.6774 - val_loss: 0.9264 - val_accuracy: 0.6487\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.8660 - accuracy: 0.6854 - val_loss: 0.9283 - val_accuracy: 0.6524\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.8688 - accuracy: 0.6854 - val_loss: 0.9045 - val_accuracy: 0.6605\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.8570 - accuracy: 0.6879 - val_loss: 0.9027 - val_accuracy: 0.6354\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.8589 - accuracy: 0.6926 - val_loss: 0.8909 - val_accuracy: 0.6760\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.8542 - accuracy: 0.6951 - val_loss: 0.8950 - val_accuracy: 0.6612\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.8457 - accuracy: 0.6983 - val_loss: 0.8984 - val_accuracy: 0.6501\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.8361 - accuracy: 0.7047 - val_loss: 0.8747 - val_accuracy: 0.6701\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.8282 - accuracy: 0.7112 - val_loss: 0.8737 - val_accuracy: 0.6731\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 4s 21ms/step - loss: 0.8189 - accuracy: 0.7190 - val_loss: 0.8842 - val_accuracy: 0.6546\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.8076 - accuracy: 0.7225 - val_loss: 0.8616 - val_accuracy: 0.6842\n",
      "Model saved to models/standard\\4px\\Composante-Diversite-NucleScore\n",
      "Validation accuracy for 4px - Composante-Diversite-NucleScore: 0.6842\n",
      "\n",
      "Training 4px/Skew-Composante-Diversite...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 5s 28ms/step - loss: 0.9443 - accuracy: 0.6588 - val_loss: 0.9380 - val_accuracy: 0.6494\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.9026 - accuracy: 0.6689 - val_loss: 0.9306 - val_accuracy: 0.6250\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.8894 - accuracy: 0.6771 - val_loss: 0.9121 - val_accuracy: 0.6561\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.8671 - accuracy: 0.6924 - val_loss: 0.9124 - val_accuracy: 0.6391\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.8602 - accuracy: 0.6911 - val_loss: 0.9257 - val_accuracy: 0.6516\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.8544 - accuracy: 0.6975 - val_loss: 0.9138 - val_accuracy: 0.6598\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.8469 - accuracy: 0.6975 - val_loss: 0.9653 - val_accuracy: 0.6612\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.8434 - accuracy: 0.6964 - val_loss: 0.9093 - val_accuracy: 0.6657\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.8388 - accuracy: 0.6979 - val_loss: 0.9526 - val_accuracy: 0.6605\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.8350 - accuracy: 0.6970 - val_loss: 0.9223 - val_accuracy: 0.6590\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.8390 - accuracy: 0.7003 - val_loss: 0.9182 - val_accuracy: 0.6716\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.8295 - accuracy: 0.7003 - val_loss: 0.9145 - val_accuracy: 0.6450\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.8233 - accuracy: 0.7003 - val_loss: 0.9106 - val_accuracy: 0.6746\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.8225 - accuracy: 0.7033 - val_loss: 0.9236 - val_accuracy: 0.6701\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.8222 - accuracy: 0.7018 - val_loss: 0.9459 - val_accuracy: 0.6657\n",
      "Model saved to models/standard\\4px\\Skew-Composante-Diversite\n",
      "Validation accuracy for 4px - Skew-Composante-Diversite: 0.6746\n",
      "\n",
      "Training 4px/Skew-Composante-NucleScore...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 5s 28ms/step - loss: 0.9978 - accuracy: 0.6481 - val_loss: 0.9827 - val_accuracy: 0.6516\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.9799 - accuracy: 0.6503 - val_loss: 0.9671 - val_accuracy: 0.6516\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.9720 - accuracy: 0.6510 - val_loss: 0.9748 - val_accuracy: 0.6516\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.9659 - accuracy: 0.6501 - val_loss: 0.9621 - val_accuracy: 0.6516\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.9582 - accuracy: 0.6518 - val_loss: 0.9398 - val_accuracy: 0.6516\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.9570 - accuracy: 0.6540 - val_loss: 0.9398 - val_accuracy: 0.6516\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.9433 - accuracy: 0.6569 - val_loss: 0.9339 - val_accuracy: 0.6516\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.9375 - accuracy: 0.6617 - val_loss: 0.9254 - val_accuracy: 0.6908\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.9418 - accuracy: 0.6636 - val_loss: 0.9099 - val_accuracy: 0.6834\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.9280 - accuracy: 0.6700 - val_loss: 0.8922 - val_accuracy: 0.7093\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.9215 - accuracy: 0.6769 - val_loss: 0.9138 - val_accuracy: 0.6524\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.9108 - accuracy: 0.6761 - val_loss: 0.8856 - val_accuracy: 0.6605\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.9225 - accuracy: 0.6616 - val_loss: 0.8733 - val_accuracy: 0.6768\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.9121 - accuracy: 0.6736 - val_loss: 0.8480 - val_accuracy: 0.7189\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.8873 - accuracy: 0.6920 - val_loss: 0.8434 - val_accuracy: 0.6790\n",
      "Model saved to models/standard\\4px\\Skew-Composante-NucleScore\n",
      "Validation accuracy for 4px - Skew-Composante-NucleScore: 0.7189\n",
      "\n",
      "Training 4px/Skew-Diversite-NucleScore...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 5s 28ms/step - loss: 0.9510 - accuracy: 0.6549 - val_loss: 0.9553 - val_accuracy: 0.6257\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.9023 - accuracy: 0.6664 - val_loss: 0.9967 - val_accuracy: 0.6487\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.8934 - accuracy: 0.6765 - val_loss: 0.9246 - val_accuracy: 0.6235\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.8884 - accuracy: 0.6724 - val_loss: 0.9240 - val_accuracy: 0.6346\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.8801 - accuracy: 0.6774 - val_loss: 0.9441 - val_accuracy: 0.6457\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.8730 - accuracy: 0.6776 - val_loss: 0.9099 - val_accuracy: 0.6391\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.8694 - accuracy: 0.6787 - val_loss: 0.9227 - val_accuracy: 0.6501\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 4s 21ms/step - loss: 0.8672 - accuracy: 0.6861 - val_loss: 0.9470 - val_accuracy: 0.6494\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.8542 - accuracy: 0.6946 - val_loss: 0.9003 - val_accuracy: 0.6820\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.8474 - accuracy: 0.7009 - val_loss: 0.8944 - val_accuracy: 0.6583\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.8380 - accuracy: 0.6998 - val_loss: 0.8811 - val_accuracy: 0.6679\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.8315 - accuracy: 0.7018 - val_loss: 0.8481 - val_accuracy: 0.6820\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.8305 - accuracy: 0.7031 - val_loss: 0.8687 - val_accuracy: 0.6672\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.8169 - accuracy: 0.7090 - val_loss: 0.8561 - val_accuracy: 0.6797\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.8139 - accuracy: 0.7073 - val_loss: 0.8417 - val_accuracy: 0.7019\n",
      "Model saved to models/standard\\4px\\Skew-Diversite-NucleScore\n",
      "Validation accuracy for 4px - Skew-Diversite-NucleScore: 0.7019\n",
      "\n",
      "Training 16px/Chargaff-Composante-Diversite...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 7s 40ms/step - loss: 0.9197 - accuracy: 0.6706 - val_loss: 0.7600 - val_accuracy: 0.6967\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.5562 - accuracy: 0.8162 - val_loss: 0.4723 - val_accuracy: 0.8417\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.4348 - accuracy: 0.8550 - val_loss: 0.4534 - val_accuracy: 0.8203\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.3876 - accuracy: 0.8769 - val_loss: 0.4042 - val_accuracy: 0.8454\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.3627 - accuracy: 0.8845 - val_loss: 0.3432 - val_accuracy: 0.8661\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 4s 21ms/step - loss: 0.3298 - accuracy: 0.8978 - val_loss: 0.3923 - val_accuracy: 0.8572\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.3071 - accuracy: 0.9040 - val_loss: 0.3257 - val_accuracy: 0.8831\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 4s 23ms/step - loss: 0.2895 - accuracy: 0.9120 - val_loss: 0.3524 - val_accuracy: 0.8942\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 4s 22ms/step - loss: 0.2803 - accuracy: 0.9142 - val_loss: 0.3559 - val_accuracy: 0.8802\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 4s 23ms/step - loss: 0.2643 - accuracy: 0.9230 - val_loss: 0.4025 - val_accuracy: 0.8536\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 4s 22ms/step - loss: 0.2649 - accuracy: 0.9179 - val_loss: 0.3632 - val_accuracy: 0.8876\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 0.2554 - accuracy: 0.9183 - val_loss: 0.3679 - val_accuracy: 0.8898\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 0.2414 - accuracy: 0.9227 - val_loss: 0.3563 - val_accuracy: 0.8898\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 4s 23ms/step - loss: 0.2381 - accuracy: 0.9234 - val_loss: 0.3616 - val_accuracy: 0.9001\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 0.2264 - accuracy: 0.9297 - val_loss: 0.4352 - val_accuracy: 0.8654\n",
      "Model saved to models/standard\\16px\\Chargaff-Composante-Diversite\n",
      "Validation accuracy for 16px - Chargaff-Composante-Diversite: 0.9001\n",
      "\n",
      "Training 16px/Chargaff-Composante-NucleScore...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 9s 46ms/step - loss: 0.9850 - accuracy: 0.6470 - val_loss: 0.8870 - val_accuracy: 0.6516\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 4s 21ms/step - loss: 0.6716 - accuracy: 0.7989 - val_loss: 0.5297 - val_accuracy: 0.8425\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 21ms/step - loss: 0.4977 - accuracy: 0.8529 - val_loss: 0.4455 - val_accuracy: 0.8676\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 4s 22ms/step - loss: 0.4338 - accuracy: 0.8745 - val_loss: 0.4030 - val_accuracy: 0.8817\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 0.4024 - accuracy: 0.8782 - val_loss: 0.4235 - val_accuracy: 0.8617\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 4s 23ms/step - loss: 0.3828 - accuracy: 0.8817 - val_loss: 0.4073 - val_accuracy: 0.8639\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 4s 23ms/step - loss: 0.3667 - accuracy: 0.8896 - val_loss: 0.3896 - val_accuracy: 0.8765\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 4s 23ms/step - loss: 0.3352 - accuracy: 0.8926 - val_loss: 0.3425 - val_accuracy: 0.8979\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 4s 22ms/step - loss: 0.3336 - accuracy: 0.8970 - val_loss: 0.3665 - val_accuracy: 0.8846\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 4s 21ms/step - loss: 0.3339 - accuracy: 0.8970 - val_loss: 0.3950 - val_accuracy: 0.8898\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.3177 - accuracy: 0.8992 - val_loss: 0.3747 - val_accuracy: 0.8920\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 4s 21ms/step - loss: 0.3096 - accuracy: 0.9039 - val_loss: 0.3733 - val_accuracy: 0.8905\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 4s 21ms/step - loss: 0.2989 - accuracy: 0.9059 - val_loss: 0.3742 - val_accuracy: 0.8920\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.2995 - accuracy: 0.9072 - val_loss: 0.4155 - val_accuracy: 0.8787\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.2872 - accuracy: 0.9118 - val_loss: 0.3609 - val_accuracy: 0.8942\n",
      "Model saved to models/standard\\16px\\Chargaff-Composante-NucleScore\n",
      "Validation accuracy for 16px - Chargaff-Composante-NucleScore: 0.8979\n",
      "\n",
      "Training 16px/Chargaff-Diversite-NucleScore...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 7s 40ms/step - loss: 0.9339 - accuracy: 0.6590 - val_loss: 0.8246 - val_accuracy: 0.6783\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 4s 21ms/step - loss: 0.6533 - accuracy: 0.7739 - val_loss: 0.6536 - val_accuracy: 0.7944\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.5161 - accuracy: 0.8335 - val_loss: 0.5143 - val_accuracy: 0.8025\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.4193 - accuracy: 0.8701 - val_loss: 0.4973 - val_accuracy: 0.8284\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.3861 - accuracy: 0.8806 - val_loss: 0.4148 - val_accuracy: 0.8676\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 4s 21ms/step - loss: 0.3417 - accuracy: 0.9000 - val_loss: 0.3879 - val_accuracy: 0.8735\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 4s 22ms/step - loss: 0.3139 - accuracy: 0.9022 - val_loss: 0.3575 - val_accuracy: 0.8846\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.3008 - accuracy: 0.9075 - val_loss: 0.4797 - val_accuracy: 0.8262\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.2715 - accuracy: 0.9177 - val_loss: 0.3864 - val_accuracy: 0.8824\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 0.2674 - accuracy: 0.9155 - val_loss: 0.3789 - val_accuracy: 0.8824\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 4s 22ms/step - loss: 0.2520 - accuracy: 0.9240 - val_loss: 0.3661 - val_accuracy: 0.8905\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.2479 - accuracy: 0.9230 - val_loss: 0.3622 - val_accuracy: 0.8964\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 4s 21ms/step - loss: 0.2406 - accuracy: 0.9258 - val_loss: 0.3819 - val_accuracy: 0.8891\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.2303 - accuracy: 0.9291 - val_loss: 0.3372 - val_accuracy: 0.9009\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.2181 - accuracy: 0.9338 - val_loss: 0.4138 - val_accuracy: 0.8883\n",
      "Model saved to models/standard\\16px\\Chargaff-Diversite-NucleScore\n",
      "Validation accuracy for 16px - Chargaff-Diversite-NucleScore: 0.9009\n",
      "\n",
      "Training 16px/Chargaff-Skew-Composante...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 7s 39ms/step - loss: 0.8679 - accuracy: 0.7029 - val_loss: 0.8635 - val_accuracy: 0.6901\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 4s 21ms/step - loss: 0.7005 - accuracy: 0.7806 - val_loss: 0.7955 - val_accuracy: 0.7374\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 4s 22ms/step - loss: 0.5574 - accuracy: 0.8288 - val_loss: 0.4829 - val_accuracy: 0.8513\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.4879 - accuracy: 0.8500 - val_loss: 0.4673 - val_accuracy: 0.8550\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.4346 - accuracy: 0.8699 - val_loss: 0.4569 - val_accuracy: 0.8351\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 4s 22ms/step - loss: 0.4079 - accuracy: 0.8721 - val_loss: 0.3819 - val_accuracy: 0.8728\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 4s 22ms/step - loss: 0.3858 - accuracy: 0.8817 - val_loss: 0.3993 - val_accuracy: 0.8698\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 4s 22ms/step - loss: 0.3762 - accuracy: 0.8815 - val_loss: 0.4077 - val_accuracy: 0.8772\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 4s 21ms/step - loss: 0.3562 - accuracy: 0.8885 - val_loss: 0.3900 - val_accuracy: 0.8691\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 4s 21ms/step - loss: 0.3500 - accuracy: 0.8919 - val_loss: 0.3773 - val_accuracy: 0.8794\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 4s 22ms/step - loss: 0.3519 - accuracy: 0.8904 - val_loss: 0.3789 - val_accuracy: 0.8750\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.3351 - accuracy: 0.8987 - val_loss: 0.4389 - val_accuracy: 0.8447\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 4s 21ms/step - loss: 0.3278 - accuracy: 0.8985 - val_loss: 0.3867 - val_accuracy: 0.8765\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.3185 - accuracy: 0.9042 - val_loss: 0.3763 - val_accuracy: 0.8765\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.3136 - accuracy: 0.9004 - val_loss: 0.4169 - val_accuracy: 0.8528\n",
      "Model saved to models/standard\\16px\\Chargaff-Skew-Composante\n",
      "Validation accuracy for 16px - Chargaff-Skew-Composante: 0.8794\n",
      "\n",
      "Training 16px/Chargaff-Skew-Diversite...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 8s 43ms/step - loss: 0.8419 - accuracy: 0.7090 - val_loss: 1.1706 - val_accuracy: 0.6561\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.6454 - accuracy: 0.7752 - val_loss: 0.8918 - val_accuracy: 0.7219\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 4s 21ms/step - loss: 0.5163 - accuracy: 0.8315 - val_loss: 0.7147 - val_accuracy: 0.7515\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 4s 21ms/step - loss: 0.4486 - accuracy: 0.8520 - val_loss: 0.5773 - val_accuracy: 0.7766\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 4s 23ms/step - loss: 0.3835 - accuracy: 0.8784 - val_loss: 0.5376 - val_accuracy: 0.8114\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 4s 22ms/step - loss: 0.3538 - accuracy: 0.8871 - val_loss: 0.5398 - val_accuracy: 0.8077\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 4s 22ms/step - loss: 0.3326 - accuracy: 0.8930 - val_loss: 0.4990 - val_accuracy: 0.8247\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.3114 - accuracy: 0.9016 - val_loss: 0.4653 - val_accuracy: 0.8314\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 4s 22ms/step - loss: 0.2989 - accuracy: 0.9051 - val_loss: 0.4821 - val_accuracy: 0.8447\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 4s 22ms/step - loss: 0.2803 - accuracy: 0.9107 - val_loss: 0.5671 - val_accuracy: 0.7929\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.2625 - accuracy: 0.9157 - val_loss: 0.5273 - val_accuracy: 0.8269\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.2623 - accuracy: 0.9144 - val_loss: 0.5370 - val_accuracy: 0.8262\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.2454 - accuracy: 0.9201 - val_loss: 0.4760 - val_accuracy: 0.8595\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.2361 - accuracy: 0.9249 - val_loss: 0.4532 - val_accuracy: 0.8595\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 4s 22ms/step - loss: 0.2203 - accuracy: 0.9319 - val_loss: 0.5201 - val_accuracy: 0.8499\n",
      "Model saved to models/standard\\16px\\Chargaff-Skew-Diversite\n",
      "Validation accuracy for 16px - Chargaff-Skew-Diversite: 0.8595\n",
      "\n",
      "Training 16px/Chargaff-Skew-NucleScore...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 8s 43ms/step - loss: 0.8713 - accuracy: 0.7053 - val_loss: 0.9251 - val_accuracy: 0.6820\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.7089 - accuracy: 0.7747 - val_loss: 0.7065 - val_accuracy: 0.7596\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 4s 21ms/step - loss: 0.5481 - accuracy: 0.8378 - val_loss: 0.4871 - val_accuracy: 0.8632\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.4514 - accuracy: 0.8616 - val_loss: 0.4325 - val_accuracy: 0.8669\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.4183 - accuracy: 0.8734 - val_loss: 0.4154 - val_accuracy: 0.8713\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.3729 - accuracy: 0.8860 - val_loss: 0.4178 - val_accuracy: 0.8765\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.3574 - accuracy: 0.8885 - val_loss: 0.4198 - val_accuracy: 0.8757\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 4s 21ms/step - loss: 0.3343 - accuracy: 0.8948 - val_loss: 0.3947 - val_accuracy: 0.8817\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 4s 25ms/step - loss: 0.3267 - accuracy: 0.9005 - val_loss: 0.3919 - val_accuracy: 0.8735\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.3191 - accuracy: 0.9016 - val_loss: 0.4113 - val_accuracy: 0.8706\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 4s 21ms/step - loss: 0.3141 - accuracy: 0.9064 - val_loss: 0.4237 - val_accuracy: 0.8794\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.3096 - accuracy: 0.9020 - val_loss: 0.5961 - val_accuracy: 0.7722\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.3019 - accuracy: 0.9070 - val_loss: 0.3992 - val_accuracy: 0.8868\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.2992 - accuracy: 0.9112 - val_loss: 0.4098 - val_accuracy: 0.8750\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 4s 22ms/step - loss: 0.2969 - accuracy: 0.9059 - val_loss: 0.4187 - val_accuracy: 0.8669\n",
      "Model saved to models/standard\\16px\\Chargaff-Skew-NucleScore\n",
      "Validation accuracy for 16px - Chargaff-Skew-NucleScore: 0.8868\n",
      "\n",
      "Training 16px/Composante-Diversite-NucleScore...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 7s 41ms/step - loss: 0.9117 - accuracy: 0.6756 - val_loss: 0.7030 - val_accuracy: 0.7729\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.5957 - accuracy: 0.8042 - val_loss: 0.4825 - val_accuracy: 0.8521\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 4s 21ms/step - loss: 0.4368 - accuracy: 0.8588 - val_loss: 0.4271 - val_accuracy: 0.8617\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.3795 - accuracy: 0.8825 - val_loss: 0.3934 - val_accuracy: 0.8632\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 4s 21ms/step - loss: 0.3406 - accuracy: 0.8935 - val_loss: 0.3658 - val_accuracy: 0.8572\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.3199 - accuracy: 0.9013 - val_loss: 0.3573 - val_accuracy: 0.8957\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.2988 - accuracy: 0.9094 - val_loss: 0.4013 - val_accuracy: 0.8536\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.2875 - accuracy: 0.9123 - val_loss: 0.3719 - val_accuracy: 0.8676\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.2651 - accuracy: 0.9184 - val_loss: 0.3347 - val_accuracy: 0.8979\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.2490 - accuracy: 0.9230 - val_loss: 0.3842 - val_accuracy: 0.8713\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.2560 - accuracy: 0.9223 - val_loss: 0.3242 - val_accuracy: 0.9061\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 4s 21ms/step - loss: 0.2384 - accuracy: 0.9304 - val_loss: 0.3463 - val_accuracy: 0.9001\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 4s 21ms/step - loss: 0.2203 - accuracy: 0.9330 - val_loss: 0.3551 - val_accuracy: 0.9046\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 4s 21ms/step - loss: 0.2213 - accuracy: 0.9330 - val_loss: 0.3428 - val_accuracy: 0.8942\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.2152 - accuracy: 0.9323 - val_loss: 0.3676 - val_accuracy: 0.8935\n",
      "Model saved to models/standard\\16px\\Composante-Diversite-NucleScore\n",
      "Validation accuracy for 16px - Composante-Diversite-NucleScore: 0.9061\n",
      "\n",
      "Training 16px/Skew-Composante-Diversite...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 8s 42ms/step - loss: 0.8434 - accuracy: 0.7084 - val_loss: 0.8033 - val_accuracy: 0.7071\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.6099 - accuracy: 0.7922 - val_loss: 0.8366 - val_accuracy: 0.7271\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 4s 23ms/step - loss: 0.4731 - accuracy: 0.8443 - val_loss: 0.6849 - val_accuracy: 0.7537\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 4s 21ms/step - loss: 0.4005 - accuracy: 0.8688 - val_loss: 0.4261 - val_accuracy: 0.8447\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.3672 - accuracy: 0.8861 - val_loss: 0.7032 - val_accuracy: 0.7396\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 4s 22ms/step - loss: 0.3367 - accuracy: 0.8922 - val_loss: 0.4175 - val_accuracy: 0.8536\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.3264 - accuracy: 0.8933 - val_loss: 0.4439 - val_accuracy: 0.8565\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.2975 - accuracy: 0.9101 - val_loss: 0.4267 - val_accuracy: 0.8536\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 4s 21ms/step - loss: 0.2815 - accuracy: 0.9105 - val_loss: 0.5532 - val_accuracy: 0.8173\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 4s 21ms/step - loss: 0.2791 - accuracy: 0.9120 - val_loss: 0.4688 - val_accuracy: 0.8373\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.2693 - accuracy: 0.9140 - val_loss: 0.4460 - val_accuracy: 0.8410\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.2540 - accuracy: 0.9197 - val_loss: 0.4402 - val_accuracy: 0.8728\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.2382 - accuracy: 0.9242 - val_loss: 0.3720 - val_accuracy: 0.8839\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.2387 - accuracy: 0.9267 - val_loss: 0.5487 - val_accuracy: 0.8188\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.2264 - accuracy: 0.9317 - val_loss: 0.4463 - val_accuracy: 0.8698\n",
      "Model saved to models/standard\\16px\\Skew-Composante-Diversite\n",
      "Validation accuracy for 16px - Skew-Composante-Diversite: 0.8839\n",
      "\n",
      "Training 16px/Skew-Composante-NucleScore...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 7s 39ms/step - loss: 0.8342 - accuracy: 0.7173 - val_loss: 0.7754 - val_accuracy: 0.7352\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.6050 - accuracy: 0.8179 - val_loss: 0.5635 - val_accuracy: 0.8314\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.5035 - accuracy: 0.8490 - val_loss: 0.4479 - val_accuracy: 0.8698\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.4478 - accuracy: 0.8644 - val_loss: 0.3895 - val_accuracy: 0.8839\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.3909 - accuracy: 0.8837 - val_loss: 0.3935 - val_accuracy: 0.8831\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.3726 - accuracy: 0.8880 - val_loss: 0.4097 - val_accuracy: 0.8839\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.3537 - accuracy: 0.8920 - val_loss: 0.3388 - val_accuracy: 0.8891\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.3401 - accuracy: 0.8932 - val_loss: 0.5696 - val_accuracy: 0.8269\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.3343 - accuracy: 0.9016 - val_loss: 0.4118 - val_accuracy: 0.8957\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.3267 - accuracy: 0.9009 - val_loss: 0.3774 - val_accuracy: 0.8920\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.3045 - accuracy: 0.9079 - val_loss: 0.3936 - val_accuracy: 0.8794\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.2965 - accuracy: 0.9094 - val_loss: 0.3600 - val_accuracy: 0.8972\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.2846 - accuracy: 0.9135 - val_loss: 0.3724 - val_accuracy: 0.8994\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.2840 - accuracy: 0.9144 - val_loss: 0.4300 - val_accuracy: 0.8669\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.2847 - accuracy: 0.9151 - val_loss: 0.4280 - val_accuracy: 0.8728\n",
      "Model saved to models/standard\\16px\\Skew-Composante-NucleScore\n",
      "Validation accuracy for 16px - Skew-Composante-NucleScore: 0.8994\n",
      "\n",
      "Training 16px/Skew-Diversite-NucleScore...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 5s 27ms/step - loss: 0.8459 - accuracy: 0.7169 - val_loss: 0.9393 - val_accuracy: 0.6879\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.6408 - accuracy: 0.7817 - val_loss: 0.6851 - val_accuracy: 0.7633\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.4787 - accuracy: 0.8404 - val_loss: 0.5131 - val_accuracy: 0.8269\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.4046 - accuracy: 0.8727 - val_loss: 0.5013 - val_accuracy: 0.8092\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.3742 - accuracy: 0.8839 - val_loss: 0.5135 - val_accuracy: 0.8336\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.3252 - accuracy: 0.8985 - val_loss: 0.4388 - val_accuracy: 0.8580\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.3077 - accuracy: 0.9037 - val_loss: 0.4392 - val_accuracy: 0.8609\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.2849 - accuracy: 0.9107 - val_loss: 0.4695 - val_accuracy: 0.8321\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.2723 - accuracy: 0.9162 - val_loss: 0.4159 - val_accuracy: 0.8691\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.2660 - accuracy: 0.9168 - val_loss: 0.4263 - val_accuracy: 0.8728\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.2434 - accuracy: 0.9253 - val_loss: 0.3711 - val_accuracy: 0.8905\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.2432 - accuracy: 0.9219 - val_loss: 0.4482 - val_accuracy: 0.8587\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.2268 - accuracy: 0.9339 - val_loss: 0.5721 - val_accuracy: 0.8343\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.2195 - accuracy: 0.9332 - val_loss: 0.4133 - val_accuracy: 0.8720\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.2057 - accuracy: 0.9356 - val_loss: 0.3654 - val_accuracy: 0.8876\n",
      "Model saved to models/standard\\16px\\Skew-Diversite-NucleScore\n",
      "Validation accuracy for 16px - Skew-Diversite-NucleScore: 0.8905\n",
      "\n",
      "Training 36px/Chargaff-Composante-Diversite...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 5s 25ms/step - loss: 0.7560 - accuracy: 0.7461 - val_loss: 0.3559 - val_accuracy: 0.8846\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.2743 - accuracy: 0.9142 - val_loss: 0.3039 - val_accuracy: 0.9068\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1950 - accuracy: 0.9481 - val_loss: 0.2600 - val_accuracy: 0.9201\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1731 - accuracy: 0.9568 - val_loss: 0.3195 - val_accuracy: 0.9201\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1643 - accuracy: 0.9581 - val_loss: 0.2693 - val_accuracy: 0.9157\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1611 - accuracy: 0.9583 - val_loss: 0.2680 - val_accuracy: 0.9216\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1531 - accuracy: 0.9605 - val_loss: 0.2655 - val_accuracy: 0.9238\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1446 - accuracy: 0.9635 - val_loss: 0.2633 - val_accuracy: 0.9223\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1423 - accuracy: 0.9636 - val_loss: 0.2845 - val_accuracy: 0.9334\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1365 - accuracy: 0.9651 - val_loss: 0.2645 - val_accuracy: 0.9349\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 4s 21ms/step - loss: 0.1347 - accuracy: 0.9659 - val_loss: 0.2800 - val_accuracy: 0.9238\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1339 - accuracy: 0.9655 - val_loss: 0.3141 - val_accuracy: 0.9246\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1221 - accuracy: 0.9666 - val_loss: 0.2580 - val_accuracy: 0.9275\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1177 - accuracy: 0.9699 - val_loss: 0.3471 - val_accuracy: 0.9246\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1213 - accuracy: 0.9677 - val_loss: 0.3571 - val_accuracy: 0.9061\n",
      "Model saved to models/standard\\36px\\Chargaff-Composante-Diversite\n",
      "Validation accuracy for 36px - Chargaff-Composante-Diversite: 0.9349\n",
      "\n",
      "Training 36px/Chargaff-Composante-NucleScore...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 5s 24ms/step - loss: 0.8933 - accuracy: 0.7001 - val_loss: 0.4614 - val_accuracy: 0.8654\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.2985 - accuracy: 0.9101 - val_loss: 0.3087 - val_accuracy: 0.9105\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.2183 - accuracy: 0.9408 - val_loss: 0.3085 - val_accuracy: 0.9179\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1922 - accuracy: 0.9480 - val_loss: 0.3285 - val_accuracy: 0.9149\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1862 - accuracy: 0.9524 - val_loss: 0.2742 - val_accuracy: 0.9186\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1717 - accuracy: 0.9528 - val_loss: 0.2783 - val_accuracy: 0.9216\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1722 - accuracy: 0.9553 - val_loss: 0.2759 - val_accuracy: 0.9179\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1662 - accuracy: 0.9568 - val_loss: 0.2627 - val_accuracy: 0.9238\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1599 - accuracy: 0.9598 - val_loss: 0.2730 - val_accuracy: 0.9216\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1585 - accuracy: 0.9585 - val_loss: 0.2662 - val_accuracy: 0.9253\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1568 - accuracy: 0.9577 - val_loss: 0.3133 - val_accuracy: 0.9127\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1493 - accuracy: 0.9607 - val_loss: 0.2863 - val_accuracy: 0.9253\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1483 - accuracy: 0.9624 - val_loss: 0.3138 - val_accuracy: 0.9031\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1469 - accuracy: 0.9605 - val_loss: 0.3149 - val_accuracy: 0.9253\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1403 - accuracy: 0.9618 - val_loss: 0.3052 - val_accuracy: 0.9297\n",
      "Model saved to models/standard\\36px\\Chargaff-Composante-NucleScore\n",
      "Validation accuracy for 36px - Chargaff-Composante-NucleScore: 0.9297\n",
      "\n",
      "Training 36px/Chargaff-Diversite-NucleScore...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 4s 24ms/step - loss: 0.7864 - accuracy: 0.7433 - val_loss: 0.4144 - val_accuracy: 0.8794\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.3115 - accuracy: 0.8989 - val_loss: 0.3844 - val_accuracy: 0.9038\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.2317 - accuracy: 0.9332 - val_loss: 0.3002 - val_accuracy: 0.9053\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1903 - accuracy: 0.9502 - val_loss: 0.2649 - val_accuracy: 0.9201\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1743 - accuracy: 0.9531 - val_loss: 0.2818 - val_accuracy: 0.9105\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1673 - accuracy: 0.9577 - val_loss: 0.2631 - val_accuracy: 0.9209\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1642 - accuracy: 0.9579 - val_loss: 0.2637 - val_accuracy: 0.9268\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1529 - accuracy: 0.9614 - val_loss: 0.2642 - val_accuracy: 0.9201\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1494 - accuracy: 0.9616 - val_loss: 0.2609 - val_accuracy: 0.9275\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1429 - accuracy: 0.9605 - val_loss: 0.2625 - val_accuracy: 0.9194\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1437 - accuracy: 0.9603 - val_loss: 0.2706 - val_accuracy: 0.9186\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1369 - accuracy: 0.9635 - val_loss: 0.3502 - val_accuracy: 0.9142\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1355 - accuracy: 0.9640 - val_loss: 0.3125 - val_accuracy: 0.9253\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1263 - accuracy: 0.9660 - val_loss: 0.3146 - val_accuracy: 0.9253\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1201 - accuracy: 0.9681 - val_loss: 0.3394 - val_accuracy: 0.9149\n",
      "Model saved to models/standard\\36px\\Chargaff-Diversite-NucleScore\n",
      "Validation accuracy for 36px - Chargaff-Diversite-NucleScore: 0.9275\n",
      "\n",
      "Training 36px/Chargaff-Skew-Composante...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 5s 24ms/step - loss: 0.7978 - accuracy: 0.7339 - val_loss: 0.4231 - val_accuracy: 0.8602\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.2730 - accuracy: 0.9183 - val_loss: 0.2949 - val_accuracy: 0.9024\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.2035 - accuracy: 0.9456 - val_loss: 0.2924 - val_accuracy: 0.9216\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1868 - accuracy: 0.9505 - val_loss: 0.2815 - val_accuracy: 0.9179\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1811 - accuracy: 0.9505 - val_loss: 0.3054 - val_accuracy: 0.9179\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1663 - accuracy: 0.9559 - val_loss: 0.2616 - val_accuracy: 0.9105\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1634 - accuracy: 0.9561 - val_loss: 0.2620 - val_accuracy: 0.9268\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1536 - accuracy: 0.9611 - val_loss: 0.2641 - val_accuracy: 0.9127\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1535 - accuracy: 0.9588 - val_loss: 0.2780 - val_accuracy: 0.9194\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1525 - accuracy: 0.9616 - val_loss: 0.2755 - val_accuracy: 0.9275\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1446 - accuracy: 0.9631 - val_loss: 0.2693 - val_accuracy: 0.9268\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1382 - accuracy: 0.9625 - val_loss: 0.2788 - val_accuracy: 0.9342\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1340 - accuracy: 0.9644 - val_loss: 0.2709 - val_accuracy: 0.9268\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1343 - accuracy: 0.9631 - val_loss: 0.2778 - val_accuracy: 0.9268\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1282 - accuracy: 0.9653 - val_loss: 0.2679 - val_accuracy: 0.9283\n",
      "Model saved to models/standard\\36px\\Chargaff-Skew-Composante\n",
      "Validation accuracy for 36px - Chargaff-Skew-Composante: 0.9342\n",
      "\n",
      "Training 36px/Chargaff-Skew-Diversite...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 5s 24ms/step - loss: 0.8174 - accuracy: 0.7153 - val_loss: 0.5843 - val_accuracy: 0.8195\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.3621 - accuracy: 0.8922 - val_loss: 0.4080 - val_accuracy: 0.9083\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.2334 - accuracy: 0.9338 - val_loss: 0.3201 - val_accuracy: 0.8802\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1975 - accuracy: 0.9454 - val_loss: 0.2660 - val_accuracy: 0.9083\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1749 - accuracy: 0.9518 - val_loss: 0.2939 - val_accuracy: 0.9135\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.1682 - accuracy: 0.9577 - val_loss: 0.2712 - val_accuracy: 0.9201\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1553 - accuracy: 0.9605 - val_loss: 0.2972 - val_accuracy: 0.9179\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1509 - accuracy: 0.9605 - val_loss: 0.3176 - val_accuracy: 0.9216\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1430 - accuracy: 0.9640 - val_loss: 0.3092 - val_accuracy: 0.9216\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1371 - accuracy: 0.9631 - val_loss: 0.3597 - val_accuracy: 0.9216\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1349 - accuracy: 0.9662 - val_loss: 0.3335 - val_accuracy: 0.9260\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1235 - accuracy: 0.9651 - val_loss: 0.3191 - val_accuracy: 0.9238\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1210 - accuracy: 0.9679 - val_loss: 0.3314 - val_accuracy: 0.9275\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1220 - accuracy: 0.9660 - val_loss: 0.3537 - val_accuracy: 0.9186\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1209 - accuracy: 0.9675 - val_loss: 0.3255 - val_accuracy: 0.9253\n",
      "Model saved to models/standard\\36px\\Chargaff-Skew-Diversite\n",
      "Validation accuracy for 36px - Chargaff-Skew-Diversite: 0.9275\n",
      "\n",
      "Training 36px/Chargaff-Skew-NucleScore...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 5s 24ms/step - loss: 0.8786 - accuracy: 0.7106 - val_loss: 0.5444 - val_accuracy: 0.8728\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.3824 - accuracy: 0.8871 - val_loss: 0.3100 - val_accuracy: 0.8972\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.2505 - accuracy: 0.9273 - val_loss: 0.2731 - val_accuracy: 0.9083\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1979 - accuracy: 0.9487 - val_loss: 0.2784 - val_accuracy: 0.9209\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1861 - accuracy: 0.9507 - val_loss: 0.3400 - val_accuracy: 0.9112\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1709 - accuracy: 0.9544 - val_loss: 0.2446 - val_accuracy: 0.9246\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1668 - accuracy: 0.9553 - val_loss: 0.2556 - val_accuracy: 0.9231\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1648 - accuracy: 0.9561 - val_loss: 0.2832 - val_accuracy: 0.9209\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1600 - accuracy: 0.9588 - val_loss: 0.2875 - val_accuracy: 0.9305\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1487 - accuracy: 0.9600 - val_loss: 0.3155 - val_accuracy: 0.9246\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1474 - accuracy: 0.9596 - val_loss: 0.2986 - val_accuracy: 0.9246\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1455 - accuracy: 0.9611 - val_loss: 0.2714 - val_accuracy: 0.9231\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1424 - accuracy: 0.9642 - val_loss: 0.2864 - val_accuracy: 0.9253\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1458 - accuracy: 0.9629 - val_loss: 0.2584 - val_accuracy: 0.9290\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1366 - accuracy: 0.9627 - val_loss: 0.2691 - val_accuracy: 0.9305\n",
      "Model saved to models/standard\\36px\\Chargaff-Skew-NucleScore\n",
      "Validation accuracy for 36px - Chargaff-Skew-NucleScore: 0.9305\n",
      "\n",
      "Training 36px/Composante-Diversite-NucleScore...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 5s 24ms/step - loss: 0.8648 - accuracy: 0.7070 - val_loss: 0.5850 - val_accuracy: 0.8395\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.3226 - accuracy: 0.9027 - val_loss: 0.2879 - val_accuracy: 0.8987\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.2045 - accuracy: 0.9459 - val_loss: 0.2982 - val_accuracy: 0.9038\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1860 - accuracy: 0.9507 - val_loss: 0.2801 - val_accuracy: 0.9083\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.1674 - accuracy: 0.9568 - val_loss: 0.2701 - val_accuracy: 0.9216\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.1682 - accuracy: 0.9566 - val_loss: 0.2945 - val_accuracy: 0.9201\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 4s 22ms/step - loss: 0.1604 - accuracy: 0.9592 - val_loss: 0.3127 - val_accuracy: 0.9231\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 4s 22ms/step - loss: 0.1506 - accuracy: 0.9609 - val_loss: 0.3520 - val_accuracy: 0.9186\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 4s 21ms/step - loss: 0.1546 - accuracy: 0.9627 - val_loss: 0.2922 - val_accuracy: 0.9260\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.1417 - accuracy: 0.9646 - val_loss: 0.3072 - val_accuracy: 0.9260\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.1380 - accuracy: 0.9648 - val_loss: 0.3320 - val_accuracy: 0.9253\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1363 - accuracy: 0.9644 - val_loss: 0.3180 - val_accuracy: 0.9297\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.1320 - accuracy: 0.9642 - val_loss: 0.2917 - val_accuracy: 0.9231\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.1277 - accuracy: 0.9670 - val_loss: 0.3101 - val_accuracy: 0.9260\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1223 - accuracy: 0.9679 - val_loss: 0.3708 - val_accuracy: 0.9149\n",
      "Model saved to models/standard\\36px\\Composante-Diversite-NucleScore\n",
      "Validation accuracy for 36px - Composante-Diversite-NucleScore: 0.9297\n",
      "\n",
      "Training 36px/Skew-Composante-Diversite...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 5s 26ms/step - loss: 0.8139 - accuracy: 0.7147 - val_loss: 0.5578 - val_accuracy: 0.8284\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.3602 - accuracy: 0.8956 - val_loss: 0.3044 - val_accuracy: 0.9075\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.2138 - accuracy: 0.9397 - val_loss: 0.3068 - val_accuracy: 0.9031\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.1807 - accuracy: 0.9513 - val_loss: 0.2995 - val_accuracy: 0.9201\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 4s 21ms/step - loss: 0.1681 - accuracy: 0.9528 - val_loss: 0.3341 - val_accuracy: 0.9068\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.1555 - accuracy: 0.9579 - val_loss: 0.2748 - val_accuracy: 0.9305\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.1452 - accuracy: 0.9600 - val_loss: 0.3160 - val_accuracy: 0.9135\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.1416 - accuracy: 0.9618 - val_loss: 0.2736 - val_accuracy: 0.9253\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.1361 - accuracy: 0.9620 - val_loss: 0.3468 - val_accuracy: 0.9194\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 4s 21ms/step - loss: 0.1263 - accuracy: 0.9660 - val_loss: 0.2887 - val_accuracy: 0.9275\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.1207 - accuracy: 0.9683 - val_loss: 0.3111 - val_accuracy: 0.9275\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.1207 - accuracy: 0.9675 - val_loss: 0.3452 - val_accuracy: 0.9216\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.1151 - accuracy: 0.9697 - val_loss: 0.3263 - val_accuracy: 0.9283\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1084 - accuracy: 0.9716 - val_loss: 0.3287 - val_accuracy: 0.9290\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1020 - accuracy: 0.9736 - val_loss: 0.3477 - val_accuracy: 0.9209\n",
      "Model saved to models/standard\\36px\\Skew-Composante-Diversite\n",
      "Validation accuracy for 36px - Skew-Composante-Diversite: 0.9305\n",
      "\n",
      "Training 36px/Skew-Composante-NucleScore...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 5s 26ms/step - loss: 0.6924 - accuracy: 0.7830 - val_loss: 0.3952 - val_accuracy: 0.8750\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.2641 - accuracy: 0.9199 - val_loss: 0.2921 - val_accuracy: 0.9105\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.2047 - accuracy: 0.9470 - val_loss: 0.2806 - val_accuracy: 0.9127\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1829 - accuracy: 0.9518 - val_loss: 0.3508 - val_accuracy: 0.8964\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1679 - accuracy: 0.9546 - val_loss: 0.2609 - val_accuracy: 0.9209\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1692 - accuracy: 0.9568 - val_loss: 0.2848 - val_accuracy: 0.9283\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1570 - accuracy: 0.9588 - val_loss: 0.2742 - val_accuracy: 0.9231\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1559 - accuracy: 0.9600 - val_loss: 0.2724 - val_accuracy: 0.9246\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1516 - accuracy: 0.9577 - val_loss: 0.3320 - val_accuracy: 0.8913\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1458 - accuracy: 0.9640 - val_loss: 0.2978 - val_accuracy: 0.9305\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1415 - accuracy: 0.9642 - val_loss: 0.3178 - val_accuracy: 0.9260\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1376 - accuracy: 0.9627 - val_loss: 0.3358 - val_accuracy: 0.9209\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1297 - accuracy: 0.9657 - val_loss: 0.2950 - val_accuracy: 0.9349\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1289 - accuracy: 0.9664 - val_loss: 0.3326 - val_accuracy: 0.9149\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1272 - accuracy: 0.9681 - val_loss: 0.2985 - val_accuracy: 0.9268\n",
      "Model saved to models/standard\\36px\\Skew-Composante-NucleScore\n",
      "Validation accuracy for 36px - Skew-Composante-NucleScore: 0.9349\n",
      "\n",
      "Training 36px/Skew-Diversite-NucleScore...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 5s 24ms/step - loss: 0.8402 - accuracy: 0.7143 - val_loss: 0.5828 - val_accuracy: 0.7929\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.4272 - accuracy: 0.8649 - val_loss: 0.3444 - val_accuracy: 0.8979\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.2686 - accuracy: 0.9210 - val_loss: 0.3954 - val_accuracy: 0.9053\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.2099 - accuracy: 0.9393 - val_loss: 0.3268 - val_accuracy: 0.9031\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1784 - accuracy: 0.9535 - val_loss: 0.3209 - val_accuracy: 0.9112\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1780 - accuracy: 0.9517 - val_loss: 0.2807 - val_accuracy: 0.9112\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1608 - accuracy: 0.9576 - val_loss: 0.3000 - val_accuracy: 0.9216\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1483 - accuracy: 0.9590 - val_loss: 0.2646 - val_accuracy: 0.9253\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1513 - accuracy: 0.9594 - val_loss: 0.2721 - val_accuracy: 0.9216\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1408 - accuracy: 0.9640 - val_loss: 0.3784 - val_accuracy: 0.9179\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1271 - accuracy: 0.9648 - val_loss: 0.3379 - val_accuracy: 0.9061\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1335 - accuracy: 0.9618 - val_loss: 0.3509 - val_accuracy: 0.9209\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1256 - accuracy: 0.9672 - val_loss: 0.3011 - val_accuracy: 0.9260\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1197 - accuracy: 0.9668 - val_loss: 0.3368 - val_accuracy: 0.9334\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1124 - accuracy: 0.9697 - val_loss: 0.3641 - val_accuracy: 0.9223\n",
      "Model saved to models/standard\\36px\\Skew-Diversite-NucleScore\n",
      "Validation accuracy for 36px - Skew-Diversite-NucleScore: 0.9334\n",
      "\n",
      "Training 64px/Chargaff-Composante-Diversite...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 5s 24ms/step - loss: 0.8648 - accuracy: 0.7005 - val_loss: 0.4673 - val_accuracy: 0.8861\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.2826 - accuracy: 0.9138 - val_loss: 0.2728 - val_accuracy: 0.9194\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1728 - accuracy: 0.9572 - val_loss: 0.2966 - val_accuracy: 0.9053\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1648 - accuracy: 0.9568 - val_loss: 0.3090 - val_accuracy: 0.9194\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1499 - accuracy: 0.9612 - val_loss: 0.2661 - val_accuracy: 0.9246\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1422 - accuracy: 0.9655 - val_loss: 0.2581 - val_accuracy: 0.9334\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1379 - accuracy: 0.9657 - val_loss: 0.3293 - val_accuracy: 0.9260\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1263 - accuracy: 0.9668 - val_loss: 0.2821 - val_accuracy: 0.9334\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1281 - accuracy: 0.9673 - val_loss: 0.3103 - val_accuracy: 0.9334\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1208 - accuracy: 0.9686 - val_loss: 0.3329 - val_accuracy: 0.9194\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1190 - accuracy: 0.9668 - val_loss: 0.2830 - val_accuracy: 0.9334\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1151 - accuracy: 0.9703 - val_loss: 0.2713 - val_accuracy: 0.9349\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1131 - accuracy: 0.9692 - val_loss: 0.3192 - val_accuracy: 0.9275\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1114 - accuracy: 0.9716 - val_loss: 0.3183 - val_accuracy: 0.9334\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1044 - accuracy: 0.9727 - val_loss: 0.2742 - val_accuracy: 0.9327\n",
      "Model saved to models/standard\\64px\\Chargaff-Composante-Diversite\n",
      "Validation accuracy for 64px - Chargaff-Composante-Diversite: 0.9349\n",
      "\n",
      "Training 64px/Chargaff-Composante-NucleScore...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 5s 24ms/step - loss: 0.8247 - accuracy: 0.7206 - val_loss: 0.3726 - val_accuracy: 0.8802\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.2463 - accuracy: 0.9280 - val_loss: 0.3064 - val_accuracy: 0.9135\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1793 - accuracy: 0.9531 - val_loss: 0.2669 - val_accuracy: 0.9179\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1636 - accuracy: 0.9577 - val_loss: 0.3271 - val_accuracy: 0.9194\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1519 - accuracy: 0.9633 - val_loss: 0.2621 - val_accuracy: 0.9260\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1492 - accuracy: 0.9638 - val_loss: 0.3361 - val_accuracy: 0.9260\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1408 - accuracy: 0.9659 - val_loss: 0.2823 - val_accuracy: 0.9305\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1330 - accuracy: 0.9659 - val_loss: 0.2819 - val_accuracy: 0.9260\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1305 - accuracy: 0.9670 - val_loss: 0.3033 - val_accuracy: 0.9305\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1258 - accuracy: 0.9694 - val_loss: 0.3310 - val_accuracy: 0.9297\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1238 - accuracy: 0.9673 - val_loss: 0.2619 - val_accuracy: 0.9386\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1212 - accuracy: 0.9703 - val_loss: 0.2931 - val_accuracy: 0.9246\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1219 - accuracy: 0.9688 - val_loss: 0.4147 - val_accuracy: 0.9172\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1159 - accuracy: 0.9705 - val_loss: 0.2932 - val_accuracy: 0.9357\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1115 - accuracy: 0.9714 - val_loss: 0.2935 - val_accuracy: 0.9320\n",
      "Model saved to models/standard\\64px\\Chargaff-Composante-NucleScore\n",
      "Validation accuracy for 64px - Chargaff-Composante-NucleScore: 0.9386\n",
      "\n",
      "Training 64px/Chargaff-Diversite-NucleScore...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 5s 24ms/step - loss: 0.9468 - accuracy: 0.6675 - val_loss: 0.6968 - val_accuracy: 0.8750\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.4075 - accuracy: 0.8804 - val_loss: 0.3428 - val_accuracy: 0.9053\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.2257 - accuracy: 0.9367 - val_loss: 0.2582 - val_accuracy: 0.9164\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1809 - accuracy: 0.9518 - val_loss: 0.2440 - val_accuracy: 0.9320\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1553 - accuracy: 0.9592 - val_loss: 0.2760 - val_accuracy: 0.9268\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1441 - accuracy: 0.9616 - val_loss: 0.2557 - val_accuracy: 0.9371\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1381 - accuracy: 0.9624 - val_loss: 0.3201 - val_accuracy: 0.9260\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1312 - accuracy: 0.9657 - val_loss: 0.2657 - val_accuracy: 0.9357\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1300 - accuracy: 0.9642 - val_loss: 0.3084 - val_accuracy: 0.9305\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1276 - accuracy: 0.9646 - val_loss: 0.3015 - val_accuracy: 0.9357\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1176 - accuracy: 0.9692 - val_loss: 0.2598 - val_accuracy: 0.9364\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1153 - accuracy: 0.9714 - val_loss: 0.3140 - val_accuracy: 0.9149\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1172 - accuracy: 0.9696 - val_loss: 0.3138 - val_accuracy: 0.9334\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1119 - accuracy: 0.9705 - val_loss: 0.2653 - val_accuracy: 0.9386\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1044 - accuracy: 0.9718 - val_loss: 0.2576 - val_accuracy: 0.9297\n",
      "Model saved to models/standard\\64px\\Chargaff-Diversite-NucleScore\n",
      "Validation accuracy for 64px - Chargaff-Diversite-NucleScore: 0.9386\n",
      "\n",
      "Training 64px/Chargaff-Skew-Composante...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 5s 25ms/step - loss: 0.7172 - accuracy: 0.7640 - val_loss: 0.5063 - val_accuracy: 0.8395\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.2735 - accuracy: 0.9183 - val_loss: 0.3633 - val_accuracy: 0.8868\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1871 - accuracy: 0.9533 - val_loss: 0.2923 - val_accuracy: 0.9127\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1597 - accuracy: 0.9592 - val_loss: 0.2634 - val_accuracy: 0.9223\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1505 - accuracy: 0.9627 - val_loss: 0.3190 - val_accuracy: 0.9223\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1373 - accuracy: 0.9657 - val_loss: 0.3239 - val_accuracy: 0.9201\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.1305 - accuracy: 0.9677 - val_loss: 0.2916 - val_accuracy: 0.9209\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.1252 - accuracy: 0.9684 - val_loss: 0.2663 - val_accuracy: 0.9305\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1201 - accuracy: 0.9692 - val_loss: 0.3033 - val_accuracy: 0.9246\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1138 - accuracy: 0.9721 - val_loss: 0.3445 - val_accuracy: 0.9283\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1118 - accuracy: 0.9714 - val_loss: 0.3799 - val_accuracy: 0.9164\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1090 - accuracy: 0.9712 - val_loss: 0.3362 - val_accuracy: 0.9223\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1056 - accuracy: 0.9723 - val_loss: 0.3125 - val_accuracy: 0.9290\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1012 - accuracy: 0.9731 - val_loss: 0.2916 - val_accuracy: 0.9260\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.0976 - accuracy: 0.9740 - val_loss: 0.2766 - val_accuracy: 0.9327\n",
      "Model saved to models/standard\\64px\\Chargaff-Skew-Composante\n",
      "Validation accuracy for 64px - Chargaff-Skew-Composante: 0.9327\n",
      "\n",
      "Training 64px/Chargaff-Skew-Diversite...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 5s 25ms/step - loss: 0.7137 - accuracy: 0.7725 - val_loss: 0.6052 - val_accuracy: 0.7885\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.3764 - accuracy: 0.8762 - val_loss: 0.3883 - val_accuracy: 0.8920\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.2292 - accuracy: 0.9391 - val_loss: 0.2808 - val_accuracy: 0.9135\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1706 - accuracy: 0.9570 - val_loss: 0.3087 - val_accuracy: 0.9209\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1514 - accuracy: 0.9635 - val_loss: 0.3458 - val_accuracy: 0.9194\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1365 - accuracy: 0.9673 - val_loss: 0.3234 - val_accuracy: 0.9179\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1314 - accuracy: 0.9670 - val_loss: 0.3505 - val_accuracy: 0.9209\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1273 - accuracy: 0.9666 - val_loss: 0.4127 - val_accuracy: 0.9053\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1165 - accuracy: 0.9703 - val_loss: 0.3276 - val_accuracy: 0.9157\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1096 - accuracy: 0.9712 - val_loss: 0.3193 - val_accuracy: 0.9260\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.0992 - accuracy: 0.9745 - val_loss: 0.3289 - val_accuracy: 0.9349\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1003 - accuracy: 0.9738 - val_loss: 0.3714 - val_accuracy: 0.9283\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.0988 - accuracy: 0.9745 - val_loss: 0.3709 - val_accuracy: 0.9253\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.0917 - accuracy: 0.9762 - val_loss: 0.4711 - val_accuracy: 0.9083\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.0952 - accuracy: 0.9747 - val_loss: 0.3262 - val_accuracy: 0.9246\n",
      "Model saved to models/standard\\64px\\Chargaff-Skew-Diversite\n",
      "Validation accuracy for 64px - Chargaff-Skew-Diversite: 0.9349\n",
      "\n",
      "Training 64px/Chargaff-Skew-NucleScore...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 5s 24ms/step - loss: 0.7579 - accuracy: 0.7584 - val_loss: 0.5912 - val_accuracy: 0.8003\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.3428 - accuracy: 0.8885 - val_loss: 0.3439 - val_accuracy: 0.8979\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.2053 - accuracy: 0.9483 - val_loss: 0.2954 - val_accuracy: 0.9135\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1738 - accuracy: 0.9566 - val_loss: 0.2915 - val_accuracy: 0.9105\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1600 - accuracy: 0.9600 - val_loss: 0.3296 - val_accuracy: 0.9127\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1502 - accuracy: 0.9618 - val_loss: 0.2674 - val_accuracy: 0.9231\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1411 - accuracy: 0.9638 - val_loss: 0.2892 - val_accuracy: 0.9157\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1303 - accuracy: 0.9692 - val_loss: 0.2704 - val_accuracy: 0.9334\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1285 - accuracy: 0.9668 - val_loss: 0.3052 - val_accuracy: 0.9186\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1225 - accuracy: 0.9688 - val_loss: 0.3183 - val_accuracy: 0.9186\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1182 - accuracy: 0.9664 - val_loss: 0.2989 - val_accuracy: 0.9290\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1123 - accuracy: 0.9710 - val_loss: 0.3792 - val_accuracy: 0.9157\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1108 - accuracy: 0.9721 - val_loss: 0.3153 - val_accuracy: 0.9297\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1088 - accuracy: 0.9692 - val_loss: 0.2970 - val_accuracy: 0.9253\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1045 - accuracy: 0.9725 - val_loss: 0.3229 - val_accuracy: 0.9253\n",
      "Model saved to models/standard\\64px\\Chargaff-Skew-NucleScore\n",
      "Validation accuracy for 64px - Chargaff-Skew-NucleScore: 0.9334\n",
      "\n",
      "Training 64px/Composante-Diversite-NucleScore...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 5s 24ms/step - loss: 0.9603 - accuracy: 0.6529 - val_loss: 0.7962 - val_accuracy: 0.6583\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.3820 - accuracy: 0.8900 - val_loss: 0.2919 - val_accuracy: 0.9112\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1887 - accuracy: 0.9511 - val_loss: 0.2755 - val_accuracy: 0.9223\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1576 - accuracy: 0.9609 - val_loss: 0.2846 - val_accuracy: 0.9238\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1516 - accuracy: 0.9605 - val_loss: 0.2893 - val_accuracy: 0.9268\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1409 - accuracy: 0.9646 - val_loss: 0.2970 - val_accuracy: 0.9216\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1358 - accuracy: 0.9646 - val_loss: 0.2966 - val_accuracy: 0.9268\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1345 - accuracy: 0.9644 - val_loss: 0.2598 - val_accuracy: 0.9379\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1301 - accuracy: 0.9664 - val_loss: 0.2983 - val_accuracy: 0.9320\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1254 - accuracy: 0.9679 - val_loss: 0.3047 - val_accuracy: 0.9379\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1172 - accuracy: 0.9697 - val_loss: 0.3434 - val_accuracy: 0.9275\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1146 - accuracy: 0.9720 - val_loss: 0.3124 - val_accuracy: 0.9371\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1132 - accuracy: 0.9697 - val_loss: 0.3425 - val_accuracy: 0.9231\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1133 - accuracy: 0.9718 - val_loss: 0.2995 - val_accuracy: 0.9401\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1081 - accuracy: 0.9731 - val_loss: 0.2912 - val_accuracy: 0.9371\n",
      "Model saved to models/standard\\64px\\Composante-Diversite-NucleScore\n",
      "Validation accuracy for 64px - Composante-Diversite-NucleScore: 0.9401\n",
      "\n",
      "Training 64px/Skew-Composante-Diversite...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 5s 25ms/step - loss: 0.7218 - accuracy: 0.7723 - val_loss: 0.5593 - val_accuracy: 0.8166\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.3098 - accuracy: 0.9024 - val_loss: 0.3213 - val_accuracy: 0.9016\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1911 - accuracy: 0.9520 - val_loss: 0.3231 - val_accuracy: 0.9120\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1587 - accuracy: 0.9622 - val_loss: 0.3149 - val_accuracy: 0.9164\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1519 - accuracy: 0.9627 - val_loss: 0.2673 - val_accuracy: 0.9246\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1353 - accuracy: 0.9672 - val_loss: 0.2467 - val_accuracy: 0.9408\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1282 - accuracy: 0.9694 - val_loss: 0.2376 - val_accuracy: 0.9342\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1196 - accuracy: 0.9708 - val_loss: 0.3456 - val_accuracy: 0.9320\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1160 - accuracy: 0.9723 - val_loss: 0.2878 - val_accuracy: 0.9349\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1069 - accuracy: 0.9720 - val_loss: 0.3250 - val_accuracy: 0.9342\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1083 - accuracy: 0.9740 - val_loss: 0.3020 - val_accuracy: 0.9305\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1072 - accuracy: 0.9729 - val_loss: 0.3059 - val_accuracy: 0.9342\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.1044 - accuracy: 0.9732 - val_loss: 0.3383 - val_accuracy: 0.9334\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1054 - accuracy: 0.9727 - val_loss: 0.2979 - val_accuracy: 0.9305\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.0948 - accuracy: 0.9779 - val_loss: 0.3670 - val_accuracy: 0.9283\n",
      "Model saved to models/standard\\64px\\Skew-Composante-Diversite\n",
      "Validation accuracy for 64px - Skew-Composante-Diversite: 0.9408\n",
      "\n",
      "Training 64px/Skew-Composante-NucleScore...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 5s 24ms/step - loss: 0.6737 - accuracy: 0.7810 - val_loss: 0.5494 - val_accuracy: 0.8151\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.2873 - accuracy: 0.9116 - val_loss: 0.2879 - val_accuracy: 0.9157\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.1791 - accuracy: 0.9535 - val_loss: 0.3014 - val_accuracy: 0.9120\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1595 - accuracy: 0.9588 - val_loss: 0.2798 - val_accuracy: 0.9268\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1517 - accuracy: 0.9636 - val_loss: 0.3229 - val_accuracy: 0.9186\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1409 - accuracy: 0.9655 - val_loss: 0.3382 - val_accuracy: 0.9172\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1320 - accuracy: 0.9683 - val_loss: 0.3242 - val_accuracy: 0.9223\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1202 - accuracy: 0.9712 - val_loss: 0.3258 - val_accuracy: 0.9238\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1185 - accuracy: 0.9714 - val_loss: 0.2806 - val_accuracy: 0.9238\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1143 - accuracy: 0.9720 - val_loss: 0.3472 - val_accuracy: 0.9194\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1078 - accuracy: 0.9731 - val_loss: 0.4179 - val_accuracy: 0.9061\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1093 - accuracy: 0.9720 - val_loss: 0.3359 - val_accuracy: 0.9268\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1033 - accuracy: 0.9747 - val_loss: 0.3775 - val_accuracy: 0.9253\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.0991 - accuracy: 0.9742 - val_loss: 0.3543 - val_accuracy: 0.9275\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.0978 - accuracy: 0.9740 - val_loss: 0.3630 - val_accuracy: 0.9238\n",
      "Model saved to models/standard\\64px\\Skew-Composante-NucleScore\n",
      "Validation accuracy for 64px - Skew-Composante-NucleScore: 0.9275\n",
      "\n",
      "Training 64px/Skew-Diversite-NucleScore...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 5s 25ms/step - loss: 0.7428 - accuracy: 0.7540 - val_loss: 0.6294 - val_accuracy: 0.7899\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.3808 - accuracy: 0.8791 - val_loss: 0.3725 - val_accuracy: 0.8802\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.2402 - accuracy: 0.9328 - val_loss: 0.3249 - val_accuracy: 0.9090\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1783 - accuracy: 0.9587 - val_loss: 0.2429 - val_accuracy: 0.9268\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1502 - accuracy: 0.9620 - val_loss: 0.3697 - val_accuracy: 0.9157\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1468 - accuracy: 0.9618 - val_loss: 0.3177 - val_accuracy: 0.9357\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1371 - accuracy: 0.9659 - val_loss: 0.2481 - val_accuracy: 0.9364\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1376 - accuracy: 0.9664 - val_loss: 0.3239 - val_accuracy: 0.9209\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1201 - accuracy: 0.9699 - val_loss: 0.2395 - val_accuracy: 0.9371\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1165 - accuracy: 0.9720 - val_loss: 0.2951 - val_accuracy: 0.9216\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1081 - accuracy: 0.9723 - val_loss: 0.2676 - val_accuracy: 0.9334\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1085 - accuracy: 0.9721 - val_loss: 0.3026 - val_accuracy: 0.9179\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1007 - accuracy: 0.9740 - val_loss: 0.3614 - val_accuracy: 0.9320\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1006 - accuracy: 0.9734 - val_loss: 0.3479 - val_accuracy: 0.9364\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.0949 - accuracy: 0.9771 - val_loss: 0.2935 - val_accuracy: 0.9349\n",
      "Model saved to models/standard\\64px\\Skew-Diversite-NucleScore\n",
      "Validation accuracy for 64px - Skew-Diversite-NucleScore: 0.9371\n",
      "\n",
      "Training 100px/Chargaff-Composante-Diversite...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 7s 38ms/step - loss: 0.9310 - accuracy: 0.6734 - val_loss: 0.6696 - val_accuracy: 0.8536\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.3122 - accuracy: 0.9083 - val_loss: 0.2936 - val_accuracy: 0.9024\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1767 - accuracy: 0.9557 - val_loss: 0.3187 - val_accuracy: 0.9209\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1534 - accuracy: 0.9646 - val_loss: 0.3239 - val_accuracy: 0.9149\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.1466 - accuracy: 0.9657 - val_loss: 0.2870 - val_accuracy: 0.9209\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1397 - accuracy: 0.9662 - val_loss: 0.3516 - val_accuracy: 0.9127\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1326 - accuracy: 0.9672 - val_loss: 0.2869 - val_accuracy: 0.9260\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1279 - accuracy: 0.9679 - val_loss: 0.3369 - val_accuracy: 0.9216\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1291 - accuracy: 0.9675 - val_loss: 0.3209 - val_accuracy: 0.9172\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1189 - accuracy: 0.9694 - val_loss: 0.3030 - val_accuracy: 0.9283\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1199 - accuracy: 0.9703 - val_loss: 0.3144 - val_accuracy: 0.9223\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.1172 - accuracy: 0.9694 - val_loss: 0.2814 - val_accuracy: 0.9349\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.1156 - accuracy: 0.9701 - val_loss: 0.3043 - val_accuracy: 0.9246\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1092 - accuracy: 0.9738 - val_loss: 0.2871 - val_accuracy: 0.9283\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.1088 - accuracy: 0.9716 - val_loss: 0.3729 - val_accuracy: 0.9223\n",
      "Model saved to models/standard\\100px\\Chargaff-Composante-Diversite\n",
      "Validation accuracy for 100px - Chargaff-Composante-Diversite: 0.9349\n",
      "\n",
      "Training 100px/Chargaff-Composante-NucleScore...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 6s 34ms/step - loss: 0.6654 - accuracy: 0.7751 - val_loss: 0.4008 - val_accuracy: 0.8646\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.2028 - accuracy: 0.9493 - val_loss: 0.3431 - val_accuracy: 0.9209\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.1614 - accuracy: 0.9594 - val_loss: 0.3082 - val_accuracy: 0.9231\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.1555 - accuracy: 0.9627 - val_loss: 0.3018 - val_accuracy: 0.9216\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1486 - accuracy: 0.9618 - val_loss: 0.2887 - val_accuracy: 0.9179\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.1428 - accuracy: 0.9644 - val_loss: 0.2881 - val_accuracy: 0.9223\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1304 - accuracy: 0.9664 - val_loss: 0.3341 - val_accuracy: 0.9223\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1267 - accuracy: 0.9675 - val_loss: 0.3138 - val_accuracy: 0.9194\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.1277 - accuracy: 0.9666 - val_loss: 0.3454 - val_accuracy: 0.9238\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1202 - accuracy: 0.9703 - val_loss: 0.3381 - val_accuracy: 0.9209\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1204 - accuracy: 0.9684 - val_loss: 0.3084 - val_accuracy: 0.9216\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.1139 - accuracy: 0.9708 - val_loss: 0.3225 - val_accuracy: 0.9201\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 4s 21ms/step - loss: 0.1128 - accuracy: 0.9699 - val_loss: 0.2820 - val_accuracy: 0.9223\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.1112 - accuracy: 0.9718 - val_loss: 0.3155 - val_accuracy: 0.9216\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.1081 - accuracy: 0.9714 - val_loss: 0.3152 - val_accuracy: 0.9209\n",
      "Model saved to models/standard\\100px\\Chargaff-Composante-NucleScore\n",
      "Validation accuracy for 100px - Chargaff-Composante-NucleScore: 0.9238\n",
      "\n",
      "Training 100px/Chargaff-Diversite-NucleScore...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 6s 33ms/step - loss: 0.9914 - accuracy: 0.6472 - val_loss: 0.9679 - val_accuracy: 0.6516\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 4s 21ms/step - loss: 0.6012 - accuracy: 0.7941 - val_loss: 0.3173 - val_accuracy: 0.8928\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.2164 - accuracy: 0.9443 - val_loss: 0.3158 - val_accuracy: 0.9186\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1707 - accuracy: 0.9574 - val_loss: 0.3291 - val_accuracy: 0.9238\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1565 - accuracy: 0.9622 - val_loss: 0.2972 - val_accuracy: 0.9216\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1501 - accuracy: 0.9640 - val_loss: 0.2931 - val_accuracy: 0.9209\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.1445 - accuracy: 0.9640 - val_loss: 0.2894 - val_accuracy: 0.9223\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1403 - accuracy: 0.9646 - val_loss: 0.2966 - val_accuracy: 0.9268\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1354 - accuracy: 0.9653 - val_loss: 0.3022 - val_accuracy: 0.9260\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1296 - accuracy: 0.9657 - val_loss: 0.3165 - val_accuracy: 0.9260\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1234 - accuracy: 0.9649 - val_loss: 0.3283 - val_accuracy: 0.9260\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1178 - accuracy: 0.9720 - val_loss: 0.3057 - val_accuracy: 0.9268\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1165 - accuracy: 0.9703 - val_loss: 0.2807 - val_accuracy: 0.9297\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1114 - accuracy: 0.9714 - val_loss: 0.3513 - val_accuracy: 0.9157\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1128 - accuracy: 0.9708 - val_loss: 0.3013 - val_accuracy: 0.9223\n",
      "Model saved to models/standard\\100px\\Chargaff-Diversite-NucleScore\n",
      "Validation accuracy for 100px - Chargaff-Diversite-NucleScore: 0.9297\n",
      "\n",
      "Training 100px/Chargaff-Skew-Composante...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 5s 29ms/step - loss: 0.6428 - accuracy: 0.7913 - val_loss: 0.4010 - val_accuracy: 0.8669\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.2399 - accuracy: 0.9310 - val_loss: 0.3455 - val_accuracy: 0.9186\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1597 - accuracy: 0.9605 - val_loss: 0.3375 - val_accuracy: 0.9157\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1467 - accuracy: 0.9633 - val_loss: 0.3260 - val_accuracy: 0.9238\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1337 - accuracy: 0.9668 - val_loss: 0.3390 - val_accuracy: 0.9268\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1354 - accuracy: 0.9659 - val_loss: 0.3167 - val_accuracy: 0.9231\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.1284 - accuracy: 0.9677 - val_loss: 0.3271 - val_accuracy: 0.9268\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1192 - accuracy: 0.9718 - val_loss: 0.2979 - val_accuracy: 0.9231\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.1248 - accuracy: 0.9684 - val_loss: 0.2997 - val_accuracy: 0.9312\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.1139 - accuracy: 0.9731 - val_loss: 0.3260 - val_accuracy: 0.9216\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1112 - accuracy: 0.9718 - val_loss: 0.2953 - val_accuracy: 0.9231\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1097 - accuracy: 0.9718 - val_loss: 0.3409 - val_accuracy: 0.9216\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1072 - accuracy: 0.9723 - val_loss: 0.4134 - val_accuracy: 0.9216\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1063 - accuracy: 0.9718 - val_loss: 0.3673 - val_accuracy: 0.9268\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.0979 - accuracy: 0.9751 - val_loss: 0.4052 - val_accuracy: 0.9231\n",
      "Model saved to models/standard\\100px\\Chargaff-Skew-Composante\n",
      "Validation accuracy for 100px - Chargaff-Skew-Composante: 0.9312\n",
      "\n",
      "Training 100px/Chargaff-Skew-Diversite...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 6s 31ms/step - loss: 0.6652 - accuracy: 0.7878 - val_loss: 0.4833 - val_accuracy: 0.8321\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.2846 - accuracy: 0.9125 - val_loss: 0.3724 - val_accuracy: 0.8928\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1784 - accuracy: 0.9544 - val_loss: 0.3474 - val_accuracy: 0.9142\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1588 - accuracy: 0.9600 - val_loss: 0.3629 - val_accuracy: 0.9068\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.1425 - accuracy: 0.9651 - val_loss: 0.3127 - val_accuracy: 0.9297\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1358 - accuracy: 0.9672 - val_loss: 0.3800 - val_accuracy: 0.9172\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.1272 - accuracy: 0.9677 - val_loss: 0.3016 - val_accuracy: 0.9334\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1234 - accuracy: 0.9692 - val_loss: 0.3026 - val_accuracy: 0.9312\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1149 - accuracy: 0.9705 - val_loss: 0.3709 - val_accuracy: 0.9142\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1079 - accuracy: 0.9718 - val_loss: 0.3737 - val_accuracy: 0.9290\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1090 - accuracy: 0.9708 - val_loss: 0.3306 - val_accuracy: 0.9268\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1056 - accuracy: 0.9731 - val_loss: 0.3353 - val_accuracy: 0.9223\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.1026 - accuracy: 0.9731 - val_loss: 0.2856 - val_accuracy: 0.9223\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.1017 - accuracy: 0.9718 - val_loss: 0.3138 - val_accuracy: 0.9320\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.0981 - accuracy: 0.9749 - val_loss: 0.2921 - val_accuracy: 0.9320\n",
      "Model saved to models/standard\\100px\\Chargaff-Skew-Diversite\n",
      "Validation accuracy for 100px - Chargaff-Skew-Diversite: 0.9334\n",
      "\n",
      "Training 100px/Chargaff-Skew-NucleScore...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 6s 30ms/step - loss: 0.7734 - accuracy: 0.7538 - val_loss: 0.5158 - val_accuracy: 0.8720\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.3618 - accuracy: 0.8850 - val_loss: 0.3404 - val_accuracy: 0.8817\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1960 - accuracy: 0.9461 - val_loss: 0.3388 - val_accuracy: 0.9061\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1660 - accuracy: 0.9574 - val_loss: 0.3339 - val_accuracy: 0.9223\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.1442 - accuracy: 0.9636 - val_loss: 0.3912 - val_accuracy: 0.9090\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1364 - accuracy: 0.9659 - val_loss: 0.3130 - val_accuracy: 0.9238\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1331 - accuracy: 0.9660 - val_loss: 0.3434 - val_accuracy: 0.9179\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1238 - accuracy: 0.9688 - val_loss: 0.3307 - val_accuracy: 0.9275\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1212 - accuracy: 0.9690 - val_loss: 0.3352 - val_accuracy: 0.9201\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1172 - accuracy: 0.9705 - val_loss: 0.3523 - val_accuracy: 0.9209\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1149 - accuracy: 0.9716 - val_loss: 0.2964 - val_accuracy: 0.9260\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.1106 - accuracy: 0.9721 - val_loss: 0.3094 - val_accuracy: 0.9275\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.1052 - accuracy: 0.9736 - val_loss: 0.3603 - val_accuracy: 0.9238\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1087 - accuracy: 0.9731 - val_loss: 0.3178 - val_accuracy: 0.9253\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1052 - accuracy: 0.9705 - val_loss: 0.3928 - val_accuracy: 0.9201\n",
      "Model saved to models/standard\\100px\\Chargaff-Skew-NucleScore\n",
      "Validation accuracy for 100px - Chargaff-Skew-NucleScore: 0.9275\n",
      "\n",
      "Training 100px/Composante-Diversite-NucleScore...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 6s 32ms/step - loss: 0.8288 - accuracy: 0.7127 - val_loss: 0.4779 - val_accuracy: 0.8521\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.2835 - accuracy: 0.9140 - val_loss: 0.3347 - val_accuracy: 0.8994\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1776 - accuracy: 0.9570 - val_loss: 0.3133 - val_accuracy: 0.9179\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1525 - accuracy: 0.9625 - val_loss: 0.3101 - val_accuracy: 0.9231\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1380 - accuracy: 0.9666 - val_loss: 0.2694 - val_accuracy: 0.9216\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.1340 - accuracy: 0.9662 - val_loss: 0.2485 - val_accuracy: 0.9231\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1291 - accuracy: 0.9672 - val_loss: 0.3045 - val_accuracy: 0.9238\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.1261 - accuracy: 0.9666 - val_loss: 0.2658 - val_accuracy: 0.9290\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1221 - accuracy: 0.9679 - val_loss: 0.3066 - val_accuracy: 0.9246\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1252 - accuracy: 0.9675 - val_loss: 0.2965 - val_accuracy: 0.9238\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1191 - accuracy: 0.9705 - val_loss: 0.2969 - val_accuracy: 0.9157\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1137 - accuracy: 0.9727 - val_loss: 0.3207 - val_accuracy: 0.9179\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1109 - accuracy: 0.9699 - val_loss: 0.3219 - val_accuracy: 0.9231\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1096 - accuracy: 0.9718 - val_loss: 0.3187 - val_accuracy: 0.9305\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1052 - accuracy: 0.9731 - val_loss: 0.3172 - val_accuracy: 0.9223\n",
      "Model saved to models/standard\\100px\\Composante-Diversite-NucleScore\n",
      "Validation accuracy for 100px - Composante-Diversite-NucleScore: 0.9305\n",
      "\n",
      "Training 100px/Skew-Composante-Diversite...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 7s 36ms/step - loss: 0.7430 - accuracy: 0.7618 - val_loss: 0.4986 - val_accuracy: 0.8698\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.3618 - accuracy: 0.8852 - val_loss: 0.3679 - val_accuracy: 0.8898\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 4s 22ms/step - loss: 0.2135 - accuracy: 0.9384 - val_loss: 0.3492 - val_accuracy: 0.9120\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 4s 22ms/step - loss: 0.1621 - accuracy: 0.9574 - val_loss: 0.3525 - val_accuracy: 0.9275\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.1423 - accuracy: 0.9616 - val_loss: 0.3473 - val_accuracy: 0.9186\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 4s 21ms/step - loss: 0.1411 - accuracy: 0.9633 - val_loss: 0.2913 - val_accuracy: 0.9327\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 4s 21ms/step - loss: 0.1276 - accuracy: 0.9688 - val_loss: 0.3757 - val_accuracy: 0.9201\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1183 - accuracy: 0.9714 - val_loss: 0.3420 - val_accuracy: 0.9305\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 4s 23ms/step - loss: 0.1156 - accuracy: 0.9723 - val_loss: 0.3020 - val_accuracy: 0.9334\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1030 - accuracy: 0.9738 - val_loss: 0.2981 - val_accuracy: 0.9149\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1070 - accuracy: 0.9751 - val_loss: 0.3344 - val_accuracy: 0.9246\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1030 - accuracy: 0.9749 - val_loss: 0.3542 - val_accuracy: 0.9194\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.0968 - accuracy: 0.9747 - val_loss: 0.3275 - val_accuracy: 0.9312\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.0994 - accuracy: 0.9720 - val_loss: 0.3819 - val_accuracy: 0.9297\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.0931 - accuracy: 0.9751 - val_loss: 0.2971 - val_accuracy: 0.9312\n",
      "Model saved to models/standard\\100px\\Skew-Composante-Diversite\n",
      "Validation accuracy for 100px - Skew-Composante-Diversite: 0.9334\n",
      "\n",
      "Training 100px/Skew-Composante-NucleScore...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.6932 - accuracy: 0.7798 - val_loss: 0.4493 - val_accuracy: 0.8743\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.2821 - accuracy: 0.9122 - val_loss: 0.3180 - val_accuracy: 0.9016\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1624 - accuracy: 0.9600 - val_loss: 0.3461 - val_accuracy: 0.9201\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1520 - accuracy: 0.9611 - val_loss: 0.3238 - val_accuracy: 0.9209\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1437 - accuracy: 0.9653 - val_loss: 0.3096 - val_accuracy: 0.9223\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1310 - accuracy: 0.9688 - val_loss: 0.3225 - val_accuracy: 0.9164\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1283 - accuracy: 0.9688 - val_loss: 0.2735 - val_accuracy: 0.9135\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.1264 - accuracy: 0.9688 - val_loss: 0.3028 - val_accuracy: 0.9283\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1212 - accuracy: 0.9697 - val_loss: 0.3304 - val_accuracy: 0.9297\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1210 - accuracy: 0.9686 - val_loss: 0.3257 - val_accuracy: 0.9275\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1095 - accuracy: 0.9740 - val_loss: 0.3252 - val_accuracy: 0.9290\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1076 - accuracy: 0.9727 - val_loss: 0.3806 - val_accuracy: 0.9098\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1059 - accuracy: 0.9740 - val_loss: 0.3138 - val_accuracy: 0.9201\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1085 - accuracy: 0.9725 - val_loss: 0.3166 - val_accuracy: 0.9283\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1019 - accuracy: 0.9734 - val_loss: 0.3585 - val_accuracy: 0.9283\n",
      "Model saved to models/standard\\100px\\Skew-Composante-NucleScore\n",
      "Validation accuracy for 100px - Skew-Composante-NucleScore: 0.9297\n",
      "\n",
      "Training 100px/Skew-Diversite-NucleScore...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 5s 29ms/step - loss: 0.7510 - accuracy: 0.7594 - val_loss: 0.5400 - val_accuracy: 0.8683\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.4075 - accuracy: 0.8743 - val_loss: 0.4601 - val_accuracy: 0.8728\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.2538 - accuracy: 0.9227 - val_loss: 0.3523 - val_accuracy: 0.9098\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1950 - accuracy: 0.9452 - val_loss: 0.3516 - val_accuracy: 0.9157\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1537 - accuracy: 0.9601 - val_loss: 0.3240 - val_accuracy: 0.9275\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1396 - accuracy: 0.9649 - val_loss: 0.3385 - val_accuracy: 0.9268\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1341 - accuracy: 0.9677 - val_loss: 0.3073 - val_accuracy: 0.9290\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.1232 - accuracy: 0.9673 - val_loss: 0.2937 - val_accuracy: 0.9320\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.1214 - accuracy: 0.9692 - val_loss: 0.3167 - val_accuracy: 0.9320\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 4s 22ms/step - loss: 0.1165 - accuracy: 0.9723 - val_loss: 0.2876 - val_accuracy: 0.9260\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.1139 - accuracy: 0.9708 - val_loss: 0.2825 - val_accuracy: 0.9260\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.1031 - accuracy: 0.9740 - val_loss: 0.3044 - val_accuracy: 0.9297\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 4s 21ms/step - loss: 0.1051 - accuracy: 0.9725 - val_loss: 0.3068 - val_accuracy: 0.9283\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 4s 22ms/step - loss: 0.0980 - accuracy: 0.9760 - val_loss: 0.3177 - val_accuracy: 0.9305\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.1006 - accuracy: 0.9727 - val_loss: 0.3165 - val_accuracy: 0.9297\n",
      "Model saved to models/standard\\100px\\Skew-Diversite-NucleScore\n",
      "Validation accuracy for 100px - Skew-Diversite-NucleScore: 0.9320\n"
     ]
    }
   ],
   "source": [
    "# Iterate through resolution folders\n",
    "for resolution_folder in sorted(os.listdir(images_dir), key=lambda x: int(re.search(r'\\d+', x).group())):\n",
    "\tresolution_path = os.path.join(images_dir, resolution_folder)\n",
    "\n",
    "\tif os.path.isdir(resolution_path):\n",
    "\t\t# Iterate through method folders inside resolution\n",
    "\t\tfor method_folder in os.listdir(resolution_path):\n",
    "\t\t\tmethod_path = os.path.join(resolution_path, method_folder)\n",
    "\n",
    "\t\t\tif os.path.isdir(method_path):\n",
    "\t\t\t\tprint(f\"\\nTraining {resolution_folder}/{method_folder}...\")\n",
    "\n",
    "\t\t\t\t# Data Preprocessing\n",
    "\t\t\t\tdatagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "\t\t\t\t# Use subset='training' and 'validation' for split\n",
    "\t\t\t\ttrain_data = datagen.flow_from_directory(\n",
    "\t\t\t\t\tmethod_path,\n",
    "\t\t\t\t\ttarget_size=img_size,\n",
    "\t\t\t\t\tbatch_size=batch_size,\n",
    "\t\t\t\t\tclass_mode='categorical',\n",
    "\t\t\t\t\tsubset='training'\n",
    "\t\t\t\t)\n",
    "\t\t\t\tval_data = datagen.flow_from_directory(\n",
    "\t\t\t\t\tmethod_path,\n",
    "\t\t\t\t\ttarget_size=img_size,\n",
    "\t\t\t\t\tbatch_size=batch_size,\n",
    "\t\t\t\t\tclass_mode='categorical',\n",
    "\t\t\t\t\tsubset='validation',\n",
    "\t\t\t\t\tshuffle=False\n",
    "\t\t\t\t)\n",
    "\n",
    "\t\t\t\tnum_classes = train_data.num_classes\n",
    "\t\t\t\tinput_shape = (img_size[0], img_size[1], 3)\n",
    "\n",
    "\t\t\t\t# Initialize and train the model\n",
    "\t\t\t\tmodel = cnn_model(input_shape, num_classes)\n",
    "\t\t\t\thistory = model.fit(\n",
    "\t\t\t\t\ttrain_data,\n",
    "\t\t\t\t\tvalidation_data=val_data,\n",
    "\t\t\t\t\tepochs=epochs,\n",
    "\t\t\t\t\tverbose=1\n",
    "\t\t\t\t)\n",
    "\n",
    "\t\t\t\t# Save the model\n",
    "\t\t\t\tmodel_path = os.path.join(\"models/standard\", resolution_folder, method_folder)\n",
    "\t\t\t\tos.makedirs(model_path, exist_ok=True)\n",
    "\t\t\t\tmodel_name = f\"{resolution_folder}_{method_folder}_mask_5_std.h5\"\n",
    "\t\t\t\tmodel.save(os.path.join(model_path, model_name))\n",
    "\t\t\t\tprint(f\"Model saved to {model_path}\")\n",
    "\n",
    "\t\t\t\t# Store final validation accuracy\n",
    "\t\t\t\tfinal_val_acc = max(history.history['val_accuracy'])\n",
    "\t\t\t\tkey = f\"{resolution_folder} - {method_folder}\"\n",
    "\t\t\t\tmax_accuracies[key] = final_val_acc\n",
    "\t\t\t\tprint(f\"Validation accuracy for {key}: {final_val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\theof\\AppData\\Local\\Temp\\ipykernel_44516\\22334614.py:21: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Create positions for bars\n",
    "num_bars = len(max_accuracies)\n",
    "x_positions = np.arange(num_bars)\n",
    "\n",
    "# Add extra space every 10 bars\n",
    "for i in range(10, num_bars, 10):  \n",
    "\tx_positions[i:] += 1  # Shift everything after every 10th bar\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.bar(x_positions, max_accuracies.values(), color='blue', width=0.5)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Custom x-ticks for readability\n",
    "plt.xticks(x_positions, max_accuracies.keys(), rotation=90)\n",
    "\n",
    "plt.yticks(np.arange(0, 1.1, 0.2))\n",
    "\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.title(\"CNN Validation Results\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# plt.savefig(\"../../imgs/graphs/kfold/cnn_validation_accuracy_bar_mask_5-kfold_aug2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\theof\\AppData\\Local\\Temp\\ipykernel_44516\\1426259004.py:9: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  colors = plt.cm.get_cmap(\"tab10\", len(methods))  # Use \"tab10\" color map with enough colors\n",
      "C:\\Users\\theof\\AppData\\Local\\Temp\\ipykernel_44516\\1426259004.py:31: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Extract and sort resolutions numerically\n",
    "resolutions = sorted(set(k.split(\" - \")[0] for k in max_accuracies.keys()), key=lambda x: int(x.replace(\"px\", \"\")))\n",
    "methods = sorted(set(k.split(\" - \")[1] for k in max_accuracies.keys()))\n",
    "\n",
    "# Organize data for plotting\n",
    "data = {method: [max_accuracies.get(f\"{res} - {method}\", None) for res in resolutions] for method in methods}\n",
    "\n",
    "# Define a color map for better distinction\n",
    "colors = plt.cm.get_cmap(\"tab10\", len(methods))  # Use \"tab10\" color map with enough colors\n",
    "\n",
    "# Plot the lines\n",
    "plt.figure(figsize=(16, 10))\n",
    "for i, (method, accuracies) in enumerate(data.items()):\n",
    "\tplt.plot(resolutions, accuracies, marker=\"o\", linestyle=\"-\", linewidth=2, markersize=8, label=method, color=colors(i))\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel(\"Resolution\", fontsize=12)\n",
    "plt.ylabel(\"Max Accuracy\", fontsize=12)\n",
    "plt.title(\"CNN Validation Accuracy by Resolution and Method\", fontsize=14)\n",
    "\n",
    "# Move legend outside the plot for better clarity\n",
    "plt.legend(title=\"Method\", bbox_to_anchor=(1.05, 1), loc=\"upper left\", fontsize=10)\n",
    "\n",
    "# Add a grid with transparency\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "# Improve layout to fit legend properly\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(\"../../imgs/graphs/standard/cnn_validation_accuracy_mask_5_std.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\theof\\AppData\\Local\\Temp\\ipykernel_44516\\361041927.py:16: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  colors = plt.cm.get_cmap(\"tab10\", len(methods_group1))  # Use \"tab10\" color map with enough colors\n",
      "C:\\Users\\theof\\AppData\\Local\\Temp\\ipykernel_44516\\361041927.py:37: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Extract and sort resolutions numerically\n",
    "resolutions = sorted(set(k.split(\" - \")[0] for k in max_accuracies.keys()), key=lambda x: int(x.replace(\"px\", \"\")))\n",
    "\n",
    "# Extract unique methods and split into two groups of 5\n",
    "methods = sorted(set(k.split(\" - \")[1] for k in max_accuracies.keys()))\n",
    "methods_group1 = methods[:5]\n",
    "methods_group2 = methods[5:]\n",
    "\n",
    "# Organize data for plotting\n",
    "data1 = {method: [max_accuracies.get(f\"{res} - {method}\", None) for res in resolutions] for method in methods_group1}\n",
    "data2 = {method: [max_accuracies.get(f\"{res} - {method}\", None) for res in resolutions] for method in methods_group2}\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 10), sharex=True, sharey=True)\n",
    "\n",
    "colors = plt.cm.get_cmap(\"tab10\", len(methods_group1))  # Use \"tab10\" color map with enough colors\n",
    "\n",
    "# Plot first group\n",
    "for method, accuracies in data1.items():\n",
    "\taxs[0].plot(resolutions, accuracies, marker=\"o\", label=method, color=colors(methods_group1.index(method)))\n",
    "axs[0].set_title(\"CNN Validation Accuracy (Group 1)\")\n",
    "axs[0].set_ylabel(\"Max Accuracy\")\n",
    "axs[0].legend(title=\"Method\")\n",
    "axs[0].grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "# Plot second group\n",
    "for method, accuracies in data2.items():\n",
    "\taxs[1].plot(resolutions, accuracies, marker=\"o\", label=method, color=colors(methods_group2.index(method)))\n",
    "axs[1].set_title(\"CNN Validation Accuracy (Group 2)\")\n",
    "axs[1].set_xlabel(\"Resolution\")\n",
    "axs[1].set_ylabel(\"Max Accuracy\")\n",
    "axs[1].legend(title=\"Method\")\n",
    "axs[1].grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(\"../../imgs/graphs/standard/cnn_validation_accuracy_groups_mask_5_std.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_90\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_180 (Conv2D)         (None, 28, 28, 32)        2432      \n",
      "                                                                 \n",
      " max_pooling2d_180 (MaxPool  (None, 14, 14, 32)        0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_181 (Conv2D)         (None, 10, 10, 64)        51264     \n",
      "                                                                 \n",
      " max_pooling2d_181 (MaxPool  (None, 5, 5, 64)          0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " flatten_90 (Flatten)        (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_180 (Dense)           (None, 128)               204928    \n",
      "                                                                 \n",
      " dense_181 (Dense)           (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 259269 (1012.77 KB)\n",
      "Trainable params: 259269 (1012.77 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Found 6771 images belonging to 5 classes.\n",
      "212/212 [==============================] - 3s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\theof\\AppData\\Local\\Temp\\ipykernel_44516\\3230203911.py:40: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "from keras.models import load_model\n",
    "\n",
    "# Load the model\n",
    "model_path = \"models/standard/100px/Chargaff-Composante-Diversite/100px_Chargaff-Composante-Diversite_mask_5_std.h5\"\n",
    "model = load_model(model_path)\n",
    "model.summary()\n",
    "\n",
    "# Load the test data\n",
    "test_data_dir = 'images/100px/Chargaff-Composante-Diversite'\n",
    "# 'C:/Users/theof/OneDrive/Documents/Github/genome_color_unpickler/test-raw/arrays/100px/Chargaff-Composante-Diversite'\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "\ttest_data_dir,\n",
    "\ttarget_size=img_size,\n",
    "\tbatch_size=batch_size,\n",
    "\tclass_mode='categorical',\n",
    "\tshuffle=False\n",
    ")\n",
    "# Get the true labels\n",
    "true_labels = test_generator.classes\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Get the predicted labels\n",
    "predictions = model.predict(test_generator, steps=len(test_generator), verbose=1)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.title('Confusion Matrix at 100px Resolution for Chargaff-Composante-Diversite Method')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(\"../../imgs/graphs/standard/cnn_confusion_matrix_100px_mask_5_std.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset directory\n",
    "mosaics_dir = \"mosaics\"\n",
    "# \"C:/Users/theof/OneDrive/Documents/Github/genome_color_unpickler/train-raw/mosaics\"\n",
    "\n",
    "# Training parameters\n",
    "img_size = (20, 50)  # Resize images to 64x64\n",
    "batch_size = 32\n",
    "epochs = 15\n",
    " \n",
    "# Dictionary to store max accuracies\n",
    "max_accuracies_mos = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training 4px...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 4s 18ms/step - loss: 0.9646 - accuracy: 0.6523 - val_loss: 0.9638 - val_accuracy: 0.6494\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.9226 - accuracy: 0.6658 - val_loss: 0.9175 - val_accuracy: 0.6738\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 16ms/step - loss: 0.8905 - accuracy: 0.6820 - val_loss: 0.9036 - val_accuracy: 0.6768\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 16ms/step - loss: 0.8807 - accuracy: 0.6861 - val_loss: 0.9346 - val_accuracy: 0.6679\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 16ms/step - loss: 0.8788 - accuracy: 0.6837 - val_loss: 0.9011 - val_accuracy: 0.6709\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.8628 - accuracy: 0.6889 - val_loss: 0.8630 - val_accuracy: 0.6960\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.8479 - accuracy: 0.7022 - val_loss: 0.8465 - val_accuracy: 0.7034\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.8217 - accuracy: 0.7162 - val_loss: 0.7982 - val_accuracy: 0.7337\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.8205 - accuracy: 0.7140 - val_loss: 0.8934 - val_accuracy: 0.6686\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 16ms/step - loss: 0.7959 - accuracy: 0.7304 - val_loss: 0.7961 - val_accuracy: 0.7374\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.7713 - accuracy: 0.7413 - val_loss: 0.7497 - val_accuracy: 0.7544\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.7391 - accuracy: 0.7551 - val_loss: 0.7873 - val_accuracy: 0.7337\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.7276 - accuracy: 0.7608 - val_loss: 0.7674 - val_accuracy: 0.7396\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 16ms/step - loss: 0.7322 - accuracy: 0.7586 - val_loss: 0.7104 - val_accuracy: 0.7737\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 16ms/step - loss: 0.7141 - accuracy: 0.7688 - val_loss: 0.7033 - val_accuracy: 0.7737\n",
      "Model saved to models/standard-mosaic\\4px\n",
      "Validation accuracy for 4px: 0.7737\n",
      "\n",
      "Training 16px...\n",
      "Found 5419 images belonging to 5 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\theof\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 4s 18ms/step - loss: 0.8552 - accuracy: 0.7151 - val_loss: 0.7613 - val_accuracy: 0.7419\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.6059 - accuracy: 0.8057 - val_loss: 0.7691 - val_accuracy: 0.7493\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.4636 - accuracy: 0.8527 - val_loss: 0.7395 - val_accuracy: 0.7633\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 16ms/step - loss: 0.3947 - accuracy: 0.8727 - val_loss: 0.3828 - val_accuracy: 0.8876\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.3615 - accuracy: 0.8825 - val_loss: 0.4040 - val_accuracy: 0.8713\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 16ms/step - loss: 0.3301 - accuracy: 0.8957 - val_loss: 0.4227 - val_accuracy: 0.8683\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 16ms/step - loss: 0.3066 - accuracy: 0.9051 - val_loss: 0.3470 - val_accuracy: 0.9024\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.2940 - accuracy: 0.9064 - val_loss: 0.3582 - val_accuracy: 0.8920\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.2823 - accuracy: 0.9094 - val_loss: 0.3333 - val_accuracy: 0.8979\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.2688 - accuracy: 0.9155 - val_loss: 0.4378 - val_accuracy: 0.8617\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.2581 - accuracy: 0.9171 - val_loss: 0.3109 - val_accuracy: 0.9053\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 16ms/step - loss: 0.2370 - accuracy: 0.9284 - val_loss: 0.3334 - val_accuracy: 0.9046\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.2393 - accuracy: 0.9266 - val_loss: 0.3162 - val_accuracy: 0.9046\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.2308 - accuracy: 0.9308 - val_loss: 0.3994 - val_accuracy: 0.8765\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 16ms/step - loss: 0.2155 - accuracy: 0.9334 - val_loss: 0.3148 - val_accuracy: 0.9068\n",
      "Model saved to models/standard-mosaic\\16px\n",
      "Validation accuracy for 16px: 0.9068\n",
      "\n",
      "Training 36px...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.8373 - accuracy: 0.7123 - val_loss: 0.5199 - val_accuracy: 0.8484\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 16ms/step - loss: 0.4012 - accuracy: 0.8738 - val_loss: 0.3385 - val_accuracy: 0.8876\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.2981 - accuracy: 0.9057 - val_loss: 0.2801 - val_accuracy: 0.9046\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.2488 - accuracy: 0.9229 - val_loss: 0.2562 - val_accuracy: 0.9186\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.2180 - accuracy: 0.9341 - val_loss: 0.2833 - val_accuracy: 0.9216\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.2065 - accuracy: 0.9413 - val_loss: 0.3079 - val_accuracy: 0.9098\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1824 - accuracy: 0.9507 - val_loss: 0.3050 - val_accuracy: 0.9083\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.1656 - accuracy: 0.9546 - val_loss: 0.2785 - val_accuracy: 0.9246\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.1625 - accuracy: 0.9537 - val_loss: 0.2443 - val_accuracy: 0.9408\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1422 - accuracy: 0.9616 - val_loss: 0.2612 - val_accuracy: 0.9275\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 16ms/step - loss: 0.1403 - accuracy: 0.9620 - val_loss: 0.2559 - val_accuracy: 0.9327\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1535 - accuracy: 0.9561 - val_loss: 0.2199 - val_accuracy: 0.9379\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1311 - accuracy: 0.9664 - val_loss: 0.2369 - val_accuracy: 0.9371\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 16ms/step - loss: 0.1222 - accuracy: 0.9696 - val_loss: 0.2490 - val_accuracy: 0.9342\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 16ms/step - loss: 0.1238 - accuracy: 0.9640 - val_loss: 0.2418 - val_accuracy: 0.9342\n",
      "Model saved to models/standard-mosaic\\36px\n",
      "Validation accuracy for 36px: 0.9408\n",
      "\n",
      "Training 64px...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 4s 19ms/step - loss: 0.7357 - accuracy: 0.7618 - val_loss: 0.5421 - val_accuracy: 0.8143\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.3751 - accuracy: 0.8765 - val_loss: 0.3635 - val_accuracy: 0.8891\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.2444 - accuracy: 0.9297 - val_loss: 0.2934 - val_accuracy: 0.9157\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1859 - accuracy: 0.9526 - val_loss: 0.2841 - val_accuracy: 0.9223\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1517 - accuracy: 0.9642 - val_loss: 0.2729 - val_accuracy: 0.9268\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.1397 - accuracy: 0.9653 - val_loss: 0.2492 - val_accuracy: 0.9305\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.1314 - accuracy: 0.9690 - val_loss: 0.2594 - val_accuracy: 0.9253\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 19ms/step - loss: 0.1188 - accuracy: 0.9734 - val_loss: 0.3157 - val_accuracy: 0.9216\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1185 - accuracy: 0.9727 - val_loss: 0.2725 - val_accuracy: 0.9238\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1201 - accuracy: 0.9712 - val_loss: 0.2800 - val_accuracy: 0.9305\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1056 - accuracy: 0.9745 - val_loss: 0.2657 - val_accuracy: 0.9312\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 16ms/step - loss: 0.1020 - accuracy: 0.9755 - val_loss: 0.2427 - val_accuracy: 0.9312\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1003 - accuracy: 0.9758 - val_loss: 0.2984 - val_accuracy: 0.9231\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 20ms/step - loss: 0.0972 - accuracy: 0.9771 - val_loss: 0.2725 - val_accuracy: 0.9320\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.0967 - accuracy: 0.9762 - val_loss: 0.2932 - val_accuracy: 0.9305\n",
      "Model saved to models/standard-mosaic\\64px\n",
      "Validation accuracy for 64px: 0.9320\n",
      "\n",
      "Training 100px...\n",
      "Found 5419 images belonging to 5 classes.\n",
      "Found 1352 images belonging to 5 classes.\n",
      "Epoch 1/15\n",
      "170/170 [==============================] - 4s 18ms/step - loss: 0.7077 - accuracy: 0.7762 - val_loss: 0.4385 - val_accuracy: 0.8839\n",
      "Epoch 2/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.3468 - accuracy: 0.8872 - val_loss: 0.3353 - val_accuracy: 0.9031\n",
      "Epoch 3/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.2489 - accuracy: 0.9251 - val_loss: 0.2582 - val_accuracy: 0.9246\n",
      "Epoch 4/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1761 - accuracy: 0.9552 - val_loss: 0.2512 - val_accuracy: 0.9327\n",
      "Epoch 5/15\n",
      "170/170 [==============================] - 3s 16ms/step - loss: 0.1616 - accuracy: 0.9605 - val_loss: 0.2175 - val_accuracy: 0.9327\n",
      "Epoch 6/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1429 - accuracy: 0.9649 - val_loss: 0.2264 - val_accuracy: 0.9357\n",
      "Epoch 7/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1262 - accuracy: 0.9683 - val_loss: 0.2194 - val_accuracy: 0.9386\n",
      "Epoch 8/15\n",
      "170/170 [==============================] - 3s 16ms/step - loss: 0.1174 - accuracy: 0.9720 - val_loss: 0.2185 - val_accuracy: 0.9393\n",
      "Epoch 9/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1203 - accuracy: 0.9707 - val_loss: 0.2400 - val_accuracy: 0.9371\n",
      "Epoch 10/15\n",
      "170/170 [==============================] - 3s 18ms/step - loss: 0.1125 - accuracy: 0.9694 - val_loss: 0.2157 - val_accuracy: 0.9386\n",
      "Epoch 11/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1035 - accuracy: 0.9743 - val_loss: 0.2334 - val_accuracy: 0.9423\n",
      "Epoch 12/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.1098 - accuracy: 0.9720 - val_loss: 0.2362 - val_accuracy: 0.9357\n",
      "Epoch 13/15\n",
      "170/170 [==============================] - 3s 16ms/step - loss: 0.1005 - accuracy: 0.9742 - val_loss: 0.2032 - val_accuracy: 0.9386\n",
      "Epoch 14/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.0973 - accuracy: 0.9749 - val_loss: 0.2128 - val_accuracy: 0.9401\n",
      "Epoch 15/15\n",
      "170/170 [==============================] - 3s 17ms/step - loss: 0.0978 - accuracy: 0.9738 - val_loss: 0.2154 - val_accuracy: 0.9401\n",
      "Model saved to models/standard-mosaic\\100px\n",
      "Validation accuracy for 100px: 0.9423\n"
     ]
    }
   ],
   "source": [
    "# Mosaic version (without cross-validation)\n",
    "# Iterate through resolution folders (e.g., 4px, 16px)\n",
    "for resolution_folder in sorted(os.listdir(mosaics_dir), key=lambda x: int(re.search(r'\\d+', x).group())):\n",
    "\tresolution_path = os.path.join(mosaics_dir, resolution_folder)\n",
    "\n",
    "\tif os.path.isdir(resolution_path):\n",
    "\t\tprint(f\"\\nTraining {resolution_folder}...\")\n",
    "\n",
    "\t\t# Data Preprocessing\n",
    "\t\tdatagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "\t\t# Create training and validation generators\n",
    "\t\ttrain_data = datagen.flow_from_directory(\n",
    "\t\t\tresolution_path,\n",
    "\t\t\ttarget_size=img_size,\n",
    "\t\t\tbatch_size=batch_size,\n",
    "\t\t\tclass_mode='categorical',\n",
    "\t\t\tsubset='training'\n",
    "\t\t)\n",
    "\t\tval_data = datagen.flow_from_directory(\n",
    "\t\t\tresolution_path,\n",
    "\t\t\ttarget_size=img_size,\n",
    "\t\t\tbatch_size=batch_size,\n",
    "\t\t\tclass_mode='categorical',\n",
    "\t\t\tsubset='validation',\n",
    "\t\t\tshuffle=False\n",
    "\t\t)\n",
    "\n",
    "\t\tnum_classes = train_data.num_classes\n",
    "\t\tinput_shape = (img_size[0], img_size[1], 3)\n",
    "\n",
    "\t\t# Initialize and train model\n",
    "\t\tmodel = cnn_model(input_shape, num_classes)\n",
    "\t\thistory = model.fit(\n",
    "\t\t\ttrain_data,\n",
    "\t\t\tvalidation_data=val_data,\n",
    "\t\t\tepochs=epochs,\n",
    "\t\t\tverbose=1\n",
    "\t\t)\n",
    "\n",
    "\t\t# Save the model\n",
    "\t\tmodel_path = os.path.join(\"models/standard-mosaic\", resolution_folder)\n",
    "\t\tos.makedirs(model_path, exist_ok=True)\n",
    "\t\tmodel_name = f\"{resolution_folder}_mosaic_mask_5_std.h5\"\n",
    "\t\tmodel.save(os.path.join(model_path, model_name))\n",
    "\t\tprint(f\"Model saved to {model_path}\")\n",
    "\n",
    "\t\t# Store final validation accuracy\n",
    "\t\tfinal_val_acc = max(history.history['val_accuracy'])\n",
    "\t\tmax_accuracies_mos[resolution_folder] = final_val_acc\n",
    "\t\tprint(f\"Validation accuracy for {resolution_folder}: {final_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\theof\\AppData\\Local\\Temp\\ipykernel_44516\\2427635834.py:17: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Create positions for bars\n",
    "num_bars = len(max_accuracies_mos)\n",
    "x_positions = np.arange(num_bars)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.bar(x_positions, max_accuracies_mos.values(), color='blue', width=0.5)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Custom x-ticks for readability\n",
    "plt.xticks(x_positions, max_accuracies_mos.keys(), rotation=90)\n",
    "\n",
    "plt.yticks(np.arange(0, 1.1, 0.2))\n",
    "\n",
    "plt.ylabel(\"Max Accuracy\")\n",
    "plt.title(\"CNN Validation Results\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# plt.savefig(\"../../imgs/graphs/standard_mosaic/cnn_validation_accuracy_mosaics_mask_5_std.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\theof\\AppData\\Local\\Temp\\ipykernel_44516\\2161438940.py:26: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Extract and sort resolutions numerically\n",
    "resolutions = sorted(max_accuracies_mos.keys(), key=lambda x: int(x.replace(\"px\", \"\")))\n",
    "\n",
    "# Get max accuracy values in the correct order\n",
    "accuracies = [max_accuracies_mos[res] for res in resolutions]\n",
    "\n",
    "# Plot the accuracy per resolution\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(resolutions, accuracies, marker=\"o\", linestyle=\"-\", linewidth=2, markersize=8, color=\"blue\", label=\"Accuracy\")\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel(\"Resolution\", fontsize=12)\n",
    "plt.ylabel(\"Max Accuracy\", fontsize=12)\n",
    "plt.title(\"CNN Validation Accuracy by Resolution\", fontsize=14)\n",
    "\n",
    "# Add data points on the plot\n",
    "for i, acc in enumerate(accuracies):\n",
    "    plt.text(resolutions[i], acc, f\"{acc:.2f}\", fontsize=10, ha=\"right\")\n",
    "\n",
    "# Grid and legend\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# Save and show plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig(\"../../imgs/graphs/standard-mosaic/cnn_validation_accuracy_mosaics_line_mask_5_std.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at models/standard-mosaic/100px/100px_mosaic_mask_5_aug.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Load the model for the new version\u001b[39;00m\n\u001b[0;32m      7\u001b[0m new_model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/standard-mosaic/100px/100px_mosaic_mask_5_aug.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 8\u001b[0m new_model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_model_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m new_model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Load the test data for the new version\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\theof\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\saving_api.py:262\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    255\u001b[0m         filepath,\n\u001b[0;32m    256\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    257\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[0;32m    258\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[0;32m    259\u001b[0m     )\n\u001b[0;32m    261\u001b[0m \u001b[38;5;66;03m# Legacy case.\u001b[39;00m\n\u001b[1;32m--> 262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m legacy_sm_saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    263\u001b[0m     filepath, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    264\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\theof\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\theof\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\legacy\\save.py:234\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath_str, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mexists(filepath_str):\n\u001b[1;32m--> 234\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[0;32m    235\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo file or directory found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    236\u001b[0m         )\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39misdir(filepath_str):\n\u001b[0;32m    239\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_load\u001b[38;5;241m.\u001b[39mload(\n\u001b[0;32m    240\u001b[0m             filepath_str, \u001b[38;5;28mcompile\u001b[39m, options\n\u001b[0;32m    241\u001b[0m         )\n",
      "\u001b[1;31mOSError\u001b[0m: No file or directory found at models/standard-mosaic/100px/100px_mosaic_mask_5_aug.h5"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "from keras.models import load_model\n",
    "\n",
    "# Load the model for the new version\n",
    "new_model_path = \"models/standard-mosaic/100px/100px_mosaic_mask_5_aug.h5\"\n",
    "new_model = load_model(new_model_path)\n",
    "new_model.summary()\n",
    "\n",
    "# Load the test data for the new version\n",
    "new_test_data_dir = 'mosaics/100px'\n",
    "# 'C:/Users/theof/OneDrive/Documents/Github/genome_color_unpickler/test-raw/mosaics/100px'\n",
    "\n",
    "new_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "new_test_generator = new_test_datagen.flow_from_directory(\n",
    "\tnew_test_data_dir,\n",
    "\ttarget_size=(img_size[0], img_size[1]),\n",
    "\tbatch_size=batch_size,\n",
    "\tclass_mode='categorical',\n",
    "\tshuffle=False\n",
    ")\n",
    "\n",
    "# Get the true labels for the new version\n",
    "new_true_labels = new_test_generator.classes\n",
    "new_class_labels = list(new_test_generator.class_indices.keys())\n",
    "\n",
    "# Get the predicted labels for the new version\n",
    "new_predictions = new_model.predict(new_test_generator, steps=len(new_test_generator), verbose=1)\n",
    "new_predicted_labels = np.argmax(new_predictions, axis=1)\n",
    "\n",
    "# Generate the confusion matrix for the new version\n",
    "new_cm = confusion_matrix(new_true_labels, new_predicted_labels)\n",
    "\n",
    "# Plot the confusion matrix for the new version\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(new_cm, annot=True, fmt='d', cmap='Blues', xticklabels=new_class_labels, yticklabels=new_class_labels)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.title('Confusion Matrix for Mosaic images at 100px')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(\"../../imgs/graphs/standard-mosaic/cnn_confusion_matrix_mosaics_100px_mask_5_std.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
